{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 Text generation language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "from time import time \n",
    " \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import time\n",
    "import string\n",
    "import re\n",
    "from os import listdir\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec \n",
    "import random\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "import spacy\n",
    "import talos\n",
    "import pickle\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from random import randint\n",
    "from pickle import load\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "from sklearn  import preprocessing\n",
    "from sklearn.model_selection   import cross_val_score, GridSearchCV, cross_validate, RandomizedSearchCV\n",
    "from sklearn.metrics           import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing     import LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Embedding, LSTM, Bidirectional\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second part of this work is to train a text generation language model, where a model trained on the news article titles of “sports” topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training dataset loading, assigning new column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv', header=None, na_values=None, names = ['label', 'article_title', 'article_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping label numbers to the news topic category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category_name']=df['label'].map({1:'world', 2:'sports',3:'business', 4:'sci/tech' })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting rows with the “sports” category from the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sport_training = df[df['category_name'] == 'sports'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, extracted data has been lowercased and cleaned from punctuations, non-alphabetical words and URLs with clean_doc2 function and stored to the \"sport_clean_data\" list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls (txt):\n",
    "    txt = re.sub(r'http\\S+', '', txt)\n",
    "    txt = re.sub(r'target\\S+', '', txt)\n",
    "    txt = re.sub(r'qtype\\S+', '', txt)\n",
    "    txt = re.sub(r'qcat\\S+', '', txt)\n",
    "    txt = re.sub(r'&lt;\\S+', '', txt)\n",
    "    return(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc2(doc):\n",
    "    # split into tokens by white space\n",
    "    tokens = doc.split()\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    tokens = [remove_urls(word) for word in tokens]\n",
    "    re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    tokens = [re_punc.sub('', w) for w in tokens]\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sport_clean_data = []\n",
    "for i in range(0, len(sport_training)):\n",
    "    clean_t=clean_doc2(sport_training['article_title'][i])\n",
    "    sport_clean_data.append(clean_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, cleaned text has been tokenized with 60,651 total and 9,580 unique tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sport_tokens=[]\n",
    "for w in sport_clean_data:\n",
    "    for l in w:\n",
    "        sport_tokens.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 60462\n",
      "Unique Tokens: 9579\n"
     ]
    }
   ],
   "source": [
    "print(f'Total Tokens: {len(sport_tokens)}')\n",
    "print(f'Unique Tokens: {len(set(sport_tokens))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, tokenized text has been organized into sequences with 51 words each, where first 50 words processed as predictors and the last token as label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load text data\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading sequences\n",
    "#sequences = load_doc('sequences.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 60412\n"
     ]
    }
   ],
   "source": [
    "length = 50 + 1\n",
    "sequences = list()\n",
    "for i in range(length, len(sport_tokens)+1):\n",
    "    seq = sport_tokens[i - length:i]\n",
    "    line = ' '.join(seq)\n",
    "    sequences.append(line)\n",
    "print('Total Sequences: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wizards guard blake out week ap japan celebrates suzuki breaking record on world stage no one else compares to els mismatch turns competitive as heninhardenne faces rookie serena blames headache for linz upset ap sales sun surge ahead supreme court stays dalmiya election oklahoma rallies behind white hamm gets to keep',\n",
       " 'guard blake out week ap japan celebrates suzuki breaking record on world stage no one else compares to els mismatch turns competitive as heninhardenne faces rookie serena blames headache for linz upset ap sales sun surge ahead supreme court stays dalmiya election oklahoma rallies behind white hamm gets to keep gold',\n",
       " 'blake out week ap japan celebrates suzuki breaking record on world stage no one else compares to els mismatch turns competitive as heninhardenne faces rookie serena blames headache for linz upset ap sales sun surge ahead supreme court stays dalmiya election oklahoma rallies behind white hamm gets to keep gold medal',\n",
       " 'out week ap japan celebrates suzuki breaking record on world stage no one else compares to els mismatch turns competitive as heninhardenne faces rookie serena blames headache for linz upset ap sales sun surge ahead supreme court stays dalmiya election oklahoma rallies behind white hamm gets to keep gold medal olympics',\n",
       " 'week ap japan celebrates suzuki breaking record on world stage no one else compares to els mismatch turns competitive as heninhardenne faces rookie serena blames headache for linz upset ap sales sun surge ahead supreme court stays dalmiya election oklahoma rallies behind white hamm gets to keep gold medal olympics federer']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to save text data\n",
    "def save_doc(lines, filename):\n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(filename, 'w')\n",
    "    file.write(data)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving sequences to file\n",
    "#save_doc(sequences, 'sequences.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last preprocessing step is to encode obtained 60,601 word sequences to integer numbers and labels to one-hot vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 9580\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sequences)\n",
    "tokenized_sequences = tokenizer.texts_to_sequences(sequences)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocabulary size:', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_gen_tokenizer.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saving tokenizer\n",
    "#joblib.dump(tokenizer, 'model_gen_tokenizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sequences = array(tokenized_sequences)\n",
    "X, y = tokenized_sequences[:, :-1], tokenized_sequences[:, -1]\n",
    "y = keras.utils.to_categorical(y, num_classes=vocab_size)\n",
    "seq_length = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preprocessing steps, input and label vectors X, y might be processed through a Deep Neural Network model.\n",
    "The text generation language model was trained with Bidirectional LSTM with 256 neurons and fully connected Dense layer with 128 neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout regularisation layer with 0.2 rate was added to prevent overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding vector space was feeded with 9,581 vocabulary size and the lenght of the input sequences equal 50. Each word was represented in the 10-dimensional vector space. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output layer determined with the 9,581 nodes (vocabulary size) and softmax activation function, which represents outputs as probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the model had been training with 60 epochs and the batch size of 256 for about 2.5 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 50)            479000    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               183296    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9580)              1235820   \n",
      "=================================================================\n",
      "Total params: 1,931,012\n",
      "Trainable params: 1,931,012\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /Users/shaigazy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/60\n",
      "60412/60412 [==============================] - 157s 3ms/step - loss: 7.9700 - accuracy: 0.0271\n",
      "Epoch 2/60\n",
      "60412/60412 [==============================] - 155s 3ms/step - loss: 7.6361 - accuracy: 0.0287\n",
      "Epoch 3/60\n",
      "60412/60412 [==============================] - 156s 3ms/step - loss: 7.5600 - accuracy: 0.0304\n",
      "Epoch 4/60\n",
      "60412/60412 [==============================] - 149s 2ms/step - loss: 7.4750 - accuracy: 0.0334\n",
      "Epoch 5/60\n",
      "60412/60412 [==============================] - 162s 3ms/step - loss: 7.3690 - accuracy: 0.0351\n",
      "Epoch 6/60\n",
      "60412/60412 [==============================] - 160s 3ms/step - loss: 7.2430 - accuracy: 0.0391\n",
      "Epoch 7/60\n",
      "60412/60412 [==============================] - 149s 2ms/step - loss: 7.1064 - accuracy: 0.0445\n",
      "Epoch 8/60\n",
      "60412/60412 [==============================] - 149s 2ms/step - loss: 6.9718 - accuracy: 0.0484\n",
      "Epoch 9/60\n",
      "60412/60412 [==============================] - 148s 2ms/step - loss: 6.8291 - accuracy: 0.0514\n",
      "Epoch 10/60\n",
      "60412/60412 [==============================] - 151s 2ms/step - loss: 6.6805 - accuracy: 0.0547\n",
      "Epoch 11/60\n",
      "60412/60412 [==============================] - 150s 2ms/step - loss: 6.5212 - accuracy: 0.0590\n",
      "Epoch 12/60\n",
      "60412/60412 [==============================] - 150s 2ms/step - loss: 6.3587 - accuracy: 0.0638\n",
      "Epoch 13/60\n",
      "60412/60412 [==============================] - 150s 2ms/step - loss: 6.1806 - accuracy: 0.0694\n",
      "Epoch 14/60\n",
      "60412/60412 [==============================] - 149s 2ms/step - loss: 5.9904 - accuracy: 0.0750\n",
      "Epoch 15/60\n",
      "60412/60412 [==============================] - 148s 2ms/step - loss: 5.7913 - accuracy: 0.0803\n",
      "Epoch 16/60\n",
      "60412/60412 [==============================] - 148s 2ms/step - loss: 5.5818 - accuracy: 0.0883\n",
      "Epoch 17/60\n",
      "60412/60412 [==============================] - 157s 3ms/step - loss: 5.3680 - accuracy: 0.0983\n",
      "Epoch 18/60\n",
      "60412/60412 [==============================] - 160s 3ms/step - loss: 5.1559 - accuracy: 0.1117\n",
      "Epoch 19/60\n",
      "60412/60412 [==============================] - 150s 2ms/step - loss: 4.9529 - accuracy: 0.1261\n",
      "Epoch 20/60\n",
      "60412/60412 [==============================] - 153s 3ms/step - loss: 4.7429 - accuracy: 0.1481\n",
      "Epoch 21/60\n",
      "60412/60412 [==============================] - 157s 3ms/step - loss: 4.5443 - accuracy: 0.1715\n",
      "Epoch 22/60\n",
      "60412/60412 [==============================] - 149s 2ms/step - loss: 4.3528 - accuracy: 0.1937\n",
      "Epoch 23/60\n",
      "60412/60412 [==============================] - 153s 3ms/step - loss: 4.1619 - accuracy: 0.2183\n",
      "Epoch 24/60\n",
      "60412/60412 [==============================] - 151s 2ms/step - loss: 3.9886 - accuracy: 0.2414\n",
      "Epoch 25/60\n",
      "60412/60412 [==============================] - 155s 3ms/step - loss: 3.8273 - accuracy: 0.2626\n",
      "Epoch 26/60\n",
      "60412/60412 [==============================] - 158s 3ms/step - loss: 3.6662 - accuracy: 0.2830\n",
      "Epoch 27/60\n",
      "60412/60412 [==============================] - 164s 3ms/step - loss: 3.5246 - accuracy: 0.3040\n",
      "Epoch 28/60\n",
      "60412/60412 [==============================] - 156s 3ms/step - loss: 3.3910 - accuracy: 0.3218\n",
      "Epoch 29/60\n",
      "60412/60412 [==============================] - 155s 3ms/step - loss: 3.2639 - accuracy: 0.3388\n",
      "Epoch 30/60\n",
      "60412/60412 [==============================] - 164s 3ms/step - loss: 3.1394 - accuracy: 0.3582\n",
      "Epoch 31/60\n",
      "60412/60412 [==============================] - 159s 3ms/step - loss: 3.0244 - accuracy: 0.3746\n",
      "Epoch 32/60\n",
      "60412/60412 [==============================] - 161s 3ms/step - loss: 2.9149 - accuracy: 0.3917\n",
      "Epoch 33/60\n",
      "60412/60412 [==============================] - 154s 3ms/step - loss: 2.8194 - accuracy: 0.4044\n",
      "Epoch 34/60\n",
      "60412/60412 [==============================] - 151s 3ms/step - loss: 2.7180 - accuracy: 0.4204\n",
      "Epoch 35/60\n",
      "60412/60412 [==============================] - 152s 3ms/step - loss: 2.6293 - accuracy: 0.4352\n",
      "Epoch 36/60\n",
      "60412/60412 [==============================] - 152s 3ms/step - loss: 2.5371 - accuracy: 0.4512\n",
      "Epoch 37/60\n",
      "60412/60412 [==============================] - 151s 3ms/step - loss: 2.4474 - accuracy: 0.4678\n",
      "Epoch 38/60\n",
      "60412/60412 [==============================] - 151s 2ms/step - loss: 2.3743 - accuracy: 0.4777\n",
      "Epoch 39/60\n",
      "60412/60412 [==============================] - 150s 2ms/step - loss: 2.3011 - accuracy: 0.4901\n",
      "Epoch 40/60\n",
      "60412/60412 [==============================] - 152s 3ms/step - loss: 2.2251 - accuracy: 0.5009\n",
      "Epoch 41/60\n",
      "60412/60412 [==============================] - 150s 2ms/step - loss: 2.1515 - accuracy: 0.5174\n",
      "Epoch 42/60\n",
      "60412/60412 [==============================] - 151s 2ms/step - loss: 2.0912 - accuracy: 0.5262\n",
      "Epoch 43/60\n",
      "60412/60412 [==============================] - 151s 3ms/step - loss: 2.0241 - accuracy: 0.5380\n",
      "Epoch 44/60\n",
      "60412/60412 [==============================] - 151s 2ms/step - loss: 1.9634 - accuracy: 0.5488\n",
      "Epoch 45/60\n",
      "60412/60412 [==============================] - 150s 2ms/step - loss: 1.8991 - accuracy: 0.5620\n",
      "Epoch 46/60\n",
      "60412/60412 [==============================] - 150s 2ms/step - loss: 1.8518 - accuracy: 0.5685\n",
      "Epoch 47/60\n",
      "60412/60412 [==============================] - 150s 2ms/step - loss: 1.7883 - accuracy: 0.5807\n",
      "Epoch 48/60\n",
      "60412/60412 [==============================] - 151s 2ms/step - loss: 1.7445 - accuracy: 0.5885\n",
      "Epoch 49/60\n",
      "60412/60412 [==============================] - 150s 2ms/step - loss: 1.6960 - accuracy: 0.5987\n",
      "Epoch 50/60\n",
      "60412/60412 [==============================] - 150s 2ms/step - loss: 1.6453 - accuracy: 0.6088\n",
      "Epoch 51/60\n",
      "60412/60412 [==============================] - 150s 2ms/step - loss: 1.6021 - accuracy: 0.6161\n",
      "Epoch 52/60\n",
      "60412/60412 [==============================] - 151s 2ms/step - loss: 1.5580 - accuracy: 0.6244\n",
      "Epoch 53/60\n",
      "60412/60412 [==============================] - 153s 3ms/step - loss: 1.5048 - accuracy: 0.6330\n",
      "Epoch 54/60\n",
      "60412/60412 [==============================] - 150s 2ms/step - loss: 1.4715 - accuracy: 0.6415\n",
      "Epoch 55/60\n",
      "60412/60412 [==============================] - 150s 2ms/step - loss: 1.4388 - accuracy: 0.6459\n",
      "Epoch 56/60\n",
      "60412/60412 [==============================] - 151s 3ms/step - loss: 1.3929 - accuracy: 0.6556\n",
      "Epoch 57/60\n",
      "60412/60412 [==============================] - 150s 2ms/step - loss: 1.3508 - accuracy: 0.6644\n",
      "Epoch 58/60\n",
      "60412/60412 [==============================] - 151s 2ms/step - loss: 1.3113 - accuracy: 0.6746\n",
      "Epoch 59/60\n",
      "60412/60412 [==============================] - 176s 3ms/step - loss: 1.2818 - accuracy: 0.6776\n",
      "Epoch 60/60\n",
      "60412/60412 [==============================] - 160s 3ms/step - loss: 1.2413 - accuracy: 0.6862\n",
      "\n",
      " Completed training in 9192.753790855408 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_gen4 = Sequential()\n",
    "model_gen4.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
    "model_gen4.add(Bidirectional(LSTM(128)))\n",
    "model_gen4.add(Dropout(0.2))\n",
    "model_gen4.add(Dense(128, activation='relu'))\n",
    "model_gen4.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "model_gen4.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "model_gen4.summary()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model_gen4.fit(X, y, batch_size = 256, epochs = 60, workers = 8)\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print('\\n Completed training in {} seconds.'.format(elapsed),end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving model\n",
    "model_gen4.save('model_gen4.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The language modelling model was built with a fixed length of the input text equal to 50 tokens. Therefore, in order to generate a text with this model, an input text needs to be truncated or zero-padded to the required length. In this work, the length of the sequence might be calculated as the length of any predictor of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading model\n",
    "model_gen4 = keras.models.load_model('model_gen4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading tokenizer\n",
    "tokenizer = joblib.load('model_gen_tokenizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading sequences\n",
    "sequences = load_doc('sequences.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = len(sequences[0].split()) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input text for language modelling model was randomly selected with randint function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game with toe injury journalist at centre of kenteris row is stabbed straight for ab gold helmet winners red sox starring in ads no wake forest no arizona offence comes alive dolphins get win steelers have plenty in reserve spurrier keeps quiet about s carolina job ap xm strikes back cardinals\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select a seed text\n",
    "\n",
    "random.seed(2)\n",
    "seed_text = sequences[randint(0, len(sequences))]\n",
    "print(seed_text + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, a random text was processed through function below and then trained language modelling model generated 100 samples of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sequence from a language model\n",
    "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
    "    result = list()\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # encode the text as integer\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # truncate sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "        # predict probabilities for each word\n",
    "        yhat = model.predict_classes(encoded, verbose=0)\n",
    "        # map predicted word index to word\n",
    "        out_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == yhat:\n",
    "                out_word = word\n",
    "                break\n",
    "        # append to input\n",
    "        in_text += ' ' + out_word\n",
    "        result.append(out_word)\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show their power with homers against eagles totti rout soccer bc men game in testing gamecocks gunners doping lions sign australia close through in shaky gold open semifinal fifa khan lb clinches gold chiefs in four oklahoma state former black signs journey from sven of bomb or nhl miller takes sweep of year as vikings hold their club expos early better of the capriati innings gets vote to reverse the trophy win colts brees grabs mvp award ap college angels swap mother joins test at hawaii ap pacers misses a winsa team notebook coolhead would oneyear do lead to talk\n"
     ]
    }
   ],
   "source": [
    "# generate new text\n",
    "generated = generate_seq(model_gen4, tokenizer, seq_length, seed_text, 100)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with ML and DL algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test the performance of the trained earlier ML and DL models on the generated samples, words in the text were organised to 4 sentences with 25 tokens each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted = generated.split()\n",
    "sent=[]\n",
    "#number of sentences\n",
    "sent_num = 4\n",
    "#number of words each sentence\n",
    "word_num = 25\n",
    "\n",
    "for word in range(0, sent_num):\n",
    "    s = splitted[word*word_num:(word*word_num+(word_num-1))]\n",
    "    line = ' '.join(s)\n",
    "    sent.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['show their power with homers against eagles totti rout soccer bc men game in testing gamecocks gunners doping lions sign australia close through in',\n",
       " 'gold open semifinal fifa khan lb clinches gold chiefs in four oklahoma state former black signs journey from sven of bomb or nhl miller',\n",
       " 'sweep of year as vikings hold their club expos early better of the capriati innings gets vote to reverse the trophy win colts brees',\n",
       " 'mvp award ap college angels swap mother joins test at hawaii ap pacers misses a winsa team notebook coolhead would oneyear do lead to']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF, Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading TF-IDF vectorizer and best performed Linear SVM algorithm using joblib package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = joblib.load('tfidf_vectroizer.pkl')\n",
    "model_tfidf = joblib.load('best_model_tfidf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to apply loaded vectoriser and ML model to the generated samples. Since \"sports\" topic labeled with the number \"2\" in the training dataset, y_test with four \"2\" labels has been created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tfidf = vectorizer.transform(sent)\n",
    "y_test = array(pd.Series([2]*sent_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset accuracy score: 100.0 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_tfidf.predict(X_test_tfidf)\n",
    "print('Test dataset accuracy score:', (accuracy_score(y_test, y_pred))*100,'%','\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, the model with TF-IDF vectorisation and Linear SVM algorithm performed with the accuracy score 100%, correctly predicting 4/4 sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec, Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, input text should be transformed into list of lists format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_w2v = [row.split() for row in sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, Word2vec model was uploaded and normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v = Word2Vec.load(\"word2vec.model\")\n",
    "model_w2v.init_sims(replace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the test data was created by word averaging process\n",
    "Word averaging has been performed with defined by https://gist.github.com/susanli2016/dae5c9ff3cea5744822384881fc619dd#file-word_averaging\n",
    "function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_averaging(wv, words):\n",
    "    all_words, mean = set(), []\n",
    "    \n",
    "    for word in words:\n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        elif word in wv.vocab:\n",
    "            mean.append(wv.vectors_norm[wv.vocab[word].index])\n",
    "            all_words.add(wv.vocab[word].index)\n",
    "\n",
    "    if not mean:\n",
    "        logging.warning(\"cannot compute similarity with no input %s\", words)\n",
    "        return np.zeros(wv.vector_size,)\n",
    "\n",
    "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
    "    return mean\n",
    "\n",
    "def  word_averaging_list(wv, text_list):\n",
    "    return np.vstack([word_averaging(wv, post) for post in text_list ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_w2v = word_averaging_list(model_w2v.wv, np.array(sent_w2v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the best performed Logistic Regression ML model was uploaded and applied to the generated samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mod_w2v = joblib.load('best_w2v.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset accuracy score: 100.0 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_w2v = best_mod_w2v.predict(X_test_w2v)\n",
    "print('Test dataset accuracy score:', (accuracy_score(y_test, y_pred_w2v))*100,'%','\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with Word2vec vectorisation and Logistic Regression algorithm achieved the accuracy score 100%, correctly predicting 4/4 sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C-LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uploading keras tokenizer pkl file and applying to the generated samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_C_LSTM = joblib.load('C_LSTM_tokenizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_docs_C_LSTM = tokenizer_C_LSTM.texts_to_sequences(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before uploading to the C-LSTM model, encoded test dataset was zero-padded with 90 (maximum sentence length on the training dataset). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = pad_sequences(encoded_docs_C_LSTM, maxlen = 90, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, to calculate the performance, y_test was one-hot encoded with uploaded Label encoder and Keras to_categorical tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = joblib.load('label_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = array(pd.Series([2]*sent_num))\n",
    "le1 = le.transform(y_test)\n",
    "ytest = keras.utils.to_categorical(le1,num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Keras C-LSTM model and evaluating on the generated 100 text samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_C_LSTM = keras.models.load_model('model_CNN8.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 100.000000 %\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model_C_LSTM.evaluate(Xtest, ytest, verbose=0)\n",
    "print('Test Accuracy: %f' % (acc*100), '%')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C-LSTM model performed with the accuracy score 100%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both ML and DL algorithms have been performed with the accuracy score of 100%, correctly predicting 4/4 sentences. Such high accuracy is explained by the fact that the language modelling model and ML and DL algorithms were trained on the same training dataset. In addition, such results may be obtained due to small size of the data (100 tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
