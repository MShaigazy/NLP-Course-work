{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 News articles classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "                        \n",
    "from sklearn.externals import joblib\n",
    "import pickle\n",
    "import logging\n",
    "import warnings \n",
    "from time import time \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import time\n",
    "import string\n",
    "import re\n",
    "from os import listdir\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec \n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import random\n",
    "import spacy\n",
    "import talos\n",
    "from talos.utils import hidden_layers\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "\n",
    "from sklearn  import preprocessing\n",
    "from sklearn.model_selection   import cross_val_score, GridSearchCV, cross_validate, RandomizedSearchCV\n",
    "from sklearn.metrics           import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing     import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets exploring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets loading and overview the first rows of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('train.csv', header=None, na_values=None, names = ['label', 'article_title', 'article_text'])\n",
    "test_data=pd.read_csv('test.csv', header=None, na_values=None, names = ['label', 'article_title', 'article_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>article_title</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Wizards Guard Blake Out 10-12 Week (AP)</td>\n",
       "      <td>AP - Washington Wizards point guard Steve Blak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Brief: HP acquires Synstar for \\$293M</td>\n",
       "      <td>In a move designed to help it better compete i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>US Airways #39; pilots vote for 18 salary redu...</td>\n",
       "      <td>US Airways #39; pilots voted to approve a new ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Radiation risks 'need updating'</td>\n",
       "      <td>A UK panel examining radiation risks says offi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>President's fate is on the line in Venezuela</td>\n",
       "      <td>CARACAS -- Partisans on both sides are calling...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                      article_title  \\\n",
       "0      2            Wizards Guard Blake Out 10-12 Week (AP)   \n",
       "1      4              Brief: HP acquires Synstar for \\$293M   \n",
       "2      3  US Airways #39; pilots vote for 18 salary redu...   \n",
       "3      4                    Radiation risks 'need updating'   \n",
       "4      1       President's fate is on the line in Venezuela   \n",
       "\n",
       "                                        article_text  \n",
       "0  AP - Washington Wizards point guard Steve Blak...  \n",
       "1  In a move designed to help it better compete i...  \n",
       "2  US Airways #39; pilots voted to approve a new ...  \n",
       "3  A UK panel examining radiation risks says offi...  \n",
       "4  CARACAS -- Partisans on both sides are calling...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>article_title</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Qwest: The end of the beginning</td>\n",
       "      <td>Thursday #39;s agreement between Qwest Communi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sadr Militiamen Still in Control of Iraq Shrine</td>\n",
       "      <td>NAJAF, Iraq (Reuters) - Rebel Shi'ite fighter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Google Unveils Scholar Search Tool</td>\n",
       "      <td>JACKSONVILLE, FL -- The online search engine l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Titans OT Munoz has surgery</td>\n",
       "      <td>Knoxville, TN (Sports Network) - Tennessee Tit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>When outsourcing, don't forget security, exper...</td>\n",
       "      <td>When outsourcing IT operations offshore, compa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                      article_title  \\\n",
       "0      3                    Qwest: The end of the beginning   \n",
       "1      1    Sadr Militiamen Still in Control of Iraq Shrine   \n",
       "2      4                 Google Unveils Scholar Search Tool   \n",
       "3      2                        Titans OT Munoz has surgery   \n",
       "4      4  When outsourcing, don't forget security, exper...   \n",
       "\n",
       "                                        article_text  \n",
       "0  Thursday #39;s agreement between Qwest Communi...  \n",
       "1   NAJAF, Iraq (Reuters) - Rebel Shi'ite fighter...  \n",
       "2  JACKSONVILLE, FL -- The online search engine l...  \n",
       "3  Knoxville, TN (Sports Network) - Tennessee Tit...  \n",
       "4  When outsourcing IT operations offshore, compa...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for missing and zero values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Data columns (total 3 columns):\n",
      "label            40000 non-null int64\n",
      "article_title    40000 non-null object\n",
      "article_text     40000 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 937.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000 entries, 0 to 3999\n",
      "Data columns (total 3 columns):\n",
      "label            4000 non-null int64\n",
      "article_title    4000 non-null object\n",
      "article_text     4000 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 93.8+ KB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets contain no zero and missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning appropriate column names and label mapping to the news topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining target variable\n",
    "y_train = train_data['label']\n",
    "y_test = test_data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping label numbers to the news topic category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['category_name']=train_data['label'].map({1:'world', 2:'sports',3:'business', 4:'sci/tech' })\n",
    "test_data['category_name']=test_data['label'].map({1:'world', 2:'sports',3:'business', 4:'sci/tech' })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging the news title and text columns into one to obtain more comprehensive information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['full_text'] = train_data['article_title'] + \" \" + train_data['article_text']\n",
    "test_data['full_text'] = test_data['article_title'] + \" \" + test_data['article_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>article_title</th>\n",
       "      <th>article_text</th>\n",
       "      <th>category_name</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Wizards Guard Blake Out 10-12 Week (AP)</td>\n",
       "      <td>AP - Washington Wizards point guard Steve Blak...</td>\n",
       "      <td>sports</td>\n",
       "      <td>Wizards Guard Blake Out 10-12 Week (AP) AP - W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Brief: HP acquires Synstar for \\$293M</td>\n",
       "      <td>In a move designed to help it better compete i...</td>\n",
       "      <td>sci/tech</td>\n",
       "      <td>Brief: HP acquires Synstar for \\$293M In a mov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>US Airways #39; pilots vote for 18 salary redu...</td>\n",
       "      <td>US Airways #39; pilots voted to approve a new ...</td>\n",
       "      <td>business</td>\n",
       "      <td>US Airways #39; pilots vote for 18 salary redu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Radiation risks 'need updating'</td>\n",
       "      <td>A UK panel examining radiation risks says offi...</td>\n",
       "      <td>sci/tech</td>\n",
       "      <td>Radiation risks 'need updating' A UK panel exa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>President's fate is on the line in Venezuela</td>\n",
       "      <td>CARACAS -- Partisans on both sides are calling...</td>\n",
       "      <td>world</td>\n",
       "      <td>President's fate is on the line in Venezuela C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                      article_title  \\\n",
       "0      2            Wizards Guard Blake Out 10-12 Week (AP)   \n",
       "1      4              Brief: HP acquires Synstar for \\$293M   \n",
       "2      3  US Airways #39; pilots vote for 18 salary redu...   \n",
       "3      4                    Radiation risks 'need updating'   \n",
       "4      1       President's fate is on the line in Venezuela   \n",
       "\n",
       "                                        article_text category_name  \\\n",
       "0  AP - Washington Wizards point guard Steve Blak...        sports   \n",
       "1  In a move designed to help it better compete i...      sci/tech   \n",
       "2  US Airways #39; pilots voted to approve a new ...      business   \n",
       "3  A UK panel examining radiation risks says offi...      sci/tech   \n",
       "4  CARACAS -- Partisans on both sides are calling...         world   \n",
       "\n",
       "                                           full_text  \n",
       "0  Wizards Guard Blake Out 10-12 Week (AP) AP - W...  \n",
       "1  Brief: HP acquires Synstar for \\$293M In a mov...  \n",
       "2  US Airways #39; pilots vote for 18 salary redu...  \n",
       "3  Radiation risks 'need updating' A UK panel exa...  \n",
       "4  President's fate is on the line in Venezuela C...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Training Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing and visualisation the frequency distribution of the class attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business    10000\n",
      "sci/tech    10000\n",
      "world       10000\n",
      "sports      10000\n",
      "Name: category_name, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x14bc57400>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "distr = train_data['category_name'].value_counts()\n",
    "print(distr)\n",
    "plt.figure(figsize=(10,4))\n",
    "distr.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are very well balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in the training dataset: 1537305 \n",
      "\n",
      "Total number of unique words in the training dataset: 104855 \n",
      "\n",
      "Average number of words in the training dataset: 38.432625\n"
     ]
    }
   ],
   "source": [
    "#New column with word number\n",
    "train_data['word_number'] = train_data['full_text'].apply(lambda x: len(x.split(' ')))\n",
    "\n",
    "#Number of unique words\n",
    "uniq_raw = []\n",
    "for sent in train_data['full_text']:\n",
    "    for word in (sent.split(' ')):\n",
    "        uniq_raw.append(word)\n",
    "\n",
    "print('Total number of words in the training dataset:', train_data['word_number'].sum(),'\\n')\n",
    "print('Total number of unique words in the training dataset:', len(set(uniq_raw)),'\\n')\n",
    "print('Average number of words in the training dataset:', train_data['word_number'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    40000.000000\n",
       "mean        38.432625\n",
       "std         10.529942\n",
       "min          9.000000\n",
       "25%         32.000000\n",
       "50%         38.000000\n",
       "75%         44.000000\n",
       "max        178.000000\n",
       "Name: word_number, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['word_number'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "sns.boxplot(data=train_data, x='category_name', y='word_number', width=.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x15d59ee48>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data['length'] = train_data['full_text'].str.len()\n",
    "plt.figure(figsize=(15,6))\n",
    "sns.boxplot(data=train_data, x='category_name', y='length', width=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    40000.000000\n",
       "mean       236.633875\n",
       "std         66.501613\n",
       "min        100.000000\n",
       "25%        196.000000\n",
       "50%        232.000000\n",
       "75%        266.000000\n",
       "max       1006.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>article_title</th>\n",
       "      <th>article_text</th>\n",
       "      <th>category_name</th>\n",
       "      <th>full_text</th>\n",
       "      <th>word_number</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Wizards Guard Blake Out 10-12 Week (AP)</td>\n",
       "      <td>AP - Washington Wizards point guard Steve Blak...</td>\n",
       "      <td>sports</td>\n",
       "      <td>Wizards Guard Blake Out 10-12 Week (AP) AP - W...</td>\n",
       "      <td>31</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Brief: HP acquires Synstar for \\$293M</td>\n",
       "      <td>In a move designed to help it better compete i...</td>\n",
       "      <td>sci/tech</td>\n",
       "      <td>Brief: HP acquires Synstar for \\$293M In a mov...</td>\n",
       "      <td>32</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>US Airways #39; pilots vote for 18 salary redu...</td>\n",
       "      <td>US Airways #39; pilots voted to approve a new ...</td>\n",
       "      <td>business</td>\n",
       "      <td>US Airways #39; pilots vote for 18 salary redu...</td>\n",
       "      <td>38</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Radiation risks 'need updating'</td>\n",
       "      <td>A UK panel examining radiation risks says offi...</td>\n",
       "      <td>sci/tech</td>\n",
       "      <td>Radiation risks 'need updating' A UK panel exa...</td>\n",
       "      <td>28</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>President's fate is on the line in Venezuela</td>\n",
       "      <td>CARACAS -- Partisans on both sides are calling...</td>\n",
       "      <td>world</td>\n",
       "      <td>President's fate is on the line in Venezuela C...</td>\n",
       "      <td>54</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                      article_title  \\\n",
       "0      2            Wizards Guard Blake Out 10-12 Week (AP)   \n",
       "1      4              Brief: HP acquires Synstar for \\$293M   \n",
       "2      3  US Airways #39; pilots vote for 18 salary redu...   \n",
       "3      4                    Radiation risks 'need updating'   \n",
       "4      1       President's fate is on the line in Venezuela   \n",
       "\n",
       "                                        article_text category_name  \\\n",
       "0  AP - Washington Wizards point guard Steve Blak...        sports   \n",
       "1  In a move designed to help it better compete i...      sci/tech   \n",
       "2  US Airways #39; pilots voted to approve a new ...      business   \n",
       "3  A UK panel examining radiation risks says offi...      sci/tech   \n",
       "4  CARACAS -- Partisans on both sides are calling...         world   \n",
       "\n",
       "                                           full_text  word_number  length  \n",
       "0  Wizards Guard Blake Out 10-12 Week (AP) AP - W...           31     170  \n",
       "1  Brief: HP acquires Synstar for \\$293M In a mov...           32     201  \n",
       "2  US Airways #39; pilots vote for 18 salary redu...           38     217  \n",
       "3  Radiation risks 'need updating' A UK panel exa...           28     166  \n",
       "4  President's fate is on the line in Venezuela C...           54     340  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data pre-processing stage of the training dataset includes lowercase each word and remove punctuations, non-alphabetical symbols, stopwords and one-character words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to delete URL objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls (txt):\n",
    "    txt = re.sub(r'http\\S+', '', txt)\n",
    "    txt = re.sub(r'target\\S+', '', txt)\n",
    "    txt = re.sub(r'qtype\\S+', '', txt)\n",
    "    txt = re.sub(r'qcat\\S+', '', txt)\n",
    "    return(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to clean a text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc(doc):\n",
    "    tokens = doc.split()\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    tokens = [remove_urls(word) for word in tokens]\n",
    "    re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    tokens = [re_punc.sub('', w) for w in tokens]\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "\n",
    "    return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying clean_doc function, cleaned text stored in the clean_data list. The total number of words significantly decrease from 1,537,305 to 982,083"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#document loading function\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading file\n",
    "#clean_data = load_doc('clean_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of words before cleaning: 1537305 \n",
      "\n",
      "The number of words after cleaning: 982083 \n",
      "\n",
      "The number of unique words after cleaning: 53202\n"
     ]
    }
   ],
   "source": [
    "clean_data = []\n",
    "for i in range(0, len(train_data)):\n",
    "    clean_t=clean_doc(train_data['full_text'][i])\n",
    "    clean_data.append(clean_t)\n",
    "\n",
    "uniq_clean =[]\n",
    "for sent in clean_data:\n",
    "    for word in (sent.split(' ')):\n",
    "        uniq_clean.append(word)\n",
    "\n",
    "    \n",
    "print('The number of words before cleaning:', train_data['word_number'].sum(),'\\n')    \n",
    "print('The number of words after cleaning:', sum([len(i.split()) for i in clean_data]),'\\n')\n",
    "print('The number of unique words after cleaning:', len(set(uniq_clean)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document save function\n",
    "def save_doc(lines, filename):\n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(filename, 'w')\n",
    "    file.write(data)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving file\n",
    "#filename = 'clean_data.txt'\n",
    "#save_doc(clean_data, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below allows to compare how particular row from the text was cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mText before cleaning:\u001b[0m\n",
      " Chrysler to Build Sedans in Austria  DETROIT (Reuters) - DaimlerChrysler AG's &lt;A HREF=\"http://www.investor.reuters.com/FullQuote.aspx?ticker=DCX.N target=/stocks/quickinfo/fullquote\"&gt;DCX.N&lt;/A&gt; &lt;A HREF=\"http://www.investor.reuters.com/FullQuote.aspx?ticker=DCXGn.DE target=/stocks/quickinfo/fullquote\"&gt;DCXGn.DE&lt;/A&gt;  Chrysler division on Wednesday said it will start building its  hot-selling 300C sedan at a plant operated by Magna Steyr in  Graz, Austria, early next year. \n",
      "\n",
      "\u001b[1mText after cleaning:\u001b[0m\n",
      " chrysler build sedans austria detroit reuters daimlerchrysler ags lta href lta href chrysler division wednesday said start building hotselling sedan plant operated magna steyr graz austria early next year\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1m'+'Text before cleaning:'+'\\033[0m' +'\\n', train_data['full_text'][13229], '\\n')\n",
    "print('\\033[1m'+'Text after cleaning:'+'\\033[0m'+'\\n', clean_data[13229])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning test dataset with defined earlier clean_doc text cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading file\n",
    "#clean_test_data = load_doc('clean_test_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_test_data = []\n",
    "for i in range(0, len(test_data)):\n",
    "    clean_t=clean_doc(test_data['full_text'][i])\n",
    "    clean_test_data.append(clean_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving file\n",
    "#filename = 'clean_test_data.txt'\n",
    "#save_doc(clean_test_data, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Text representation with TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is a feature engineering process, where text representation techniques such as TF-IDF and Word2vec applied to transform text data into a matrix of token counts and word embeddings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term Frequency-Inverse Document Frequency (TF-IDF) is a bag-of-words technique, which converts word sequences into numerical representation – vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying TfidfVectorizer() function with default arguments (ngram_range = (1,1), min_df =1, max_df = 1, max_features = None) on the training dataset provide with the following results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 53202\n",
      "Vocabulary content:\n",
      " [('wizards', 52271), ('guard', 19561), ('blake', 5070), ('week', 51560), ('ap', 2285), ('washington', 51305), ('point', 34934), ('steve', 44895), ('miss', 29130), ('first', 16574)]\n"
     ]
    }
   ],
   "source": [
    "print('Vocabulary size:', len(vectorizer.vocabulary_))\n",
    "#print('Vocabulary content:\\n {}'.format(vectorizer.vocabulary_))\n",
    "print('Vocabulary content:\\n {}'.format(list(vectorizer.vocabulary_.items())[:10]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, changing min_df and max_df parameters revealed that only the four most frequent terms (new, reuters, said, us) appear in 10% of the corpus, and therefore these parameters can remain the default values.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=0.1)\n",
    "X = vectorizer.fit_transform(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['new', 'reuter', 'said', 'us']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Vocabulary size:', len(vectorizer.vocabulary_))\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.1)\n",
    "X = vectorizer.fit_transform(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 53202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aaa',\n",
       " 'aachen',\n",
       " 'aal',\n",
       " 'aalborg',\n",
       " 'aap',\n",
       " 'aapl',\n",
       " 'aaplnas',\n",
       " 'aaplnasdaq',\n",
       " 'aaplo']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Vocabulary size:', len(vectorizer.vocabulary_))\n",
    "vectorizer.get_feature_names()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting IDF scores provides with information about most and less frequent words in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with lowest idf: ['year' 'compani' 'ap']\n",
      "Features with highest idf: ['kach' 'kahnlehmann' 'zyman']\n"
     ]
    }
   ],
   "source": [
    "features = np.array(vectorizer.get_feature_names())\n",
    "sort_idf = np.argsort(vectorizer.idf_)\n",
    "print('Features with lowest idf:', features[sort_idf[:3]]),'\\n'\n",
    "print('Features with highest idf:', features[sort_idf[-3:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, sorting TF-IDF scores provides with weighted relevance of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with lowest tfidf: ['backend' 'familyth' 'granular'] \n",
      "\n",
      "Features with highest tfidf: ['dilithium' 'java' 'gigaset']\n"
     ]
    }
   ],
   "source": [
    "sort_tfidf = X.max(axis=0).toarray().ravel().argsort()\n",
    "\n",
    "print('Features with lowest tfidf:',features[sort_tfidf[:3]], '\\n')\n",
    "print('Features with highest tfidf:', features[sort_tfidf[-3:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to train variuous machine learning algorithms with different numbers of ngram_range and max_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training ML algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to train machine learning algorithms such as Naïve Bayes, Linear SVM, Logistic Regression and Random Forest with different numbers of ngram_range (unigram, bigram, trigram) and max_features (7000, 15000) values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to display full information of tables\n",
    "pd.set_option('display.max_colwidth', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of hyperparameters to tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_estimators = [10, 100, 200, 400]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [30,60,90, None]\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "criterion = ['entropy', 'gini']\n",
    "\n",
    "\n",
    "\n",
    "param = [{'vec__ngram_range': ((1, 1), (1, 2), (1,3)), \n",
    "          'vec__max_features': [7000, 15000],\n",
    "          'clf'   : [LinearSVC()],\n",
    "          'clf__C':[0.05, 0.1, 0.5, 1, 5, 10]\n",
    "         },\n",
    "         \n",
    "         {'vec__ngram_range': ((1, 1), (1, 2), (1,3)), \n",
    "          'vec__max_features': [7000, 15000],\n",
    "          'clf'   : [MultinomialNB()]\n",
    "         },\n",
    "            \n",
    "         {'vec__ngram_range': ((1, 1), (1, 2), (1,3)), \n",
    "          'vec__max_features': [7000, 15000],   \n",
    "         'clf': [LogisticRegression(max_iter = 7000)],\n",
    "         'clf__solver' : ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "         'clf__penalty' : ['l2'],\n",
    "         'clf__C' : [100, 10, 1.0, 0.1, 0.01]}\n",
    "        ]\n",
    "         \n",
    "random_grid = {'vec__ngram_range': ((1, 1), (1, 2), (1,3)), \n",
    "               'vec__max_features': (7000, 15000), \n",
    "               'r_f__n_estimators': n_estimators,\n",
    "               'r_f__max_features': max_features,\n",
    "               'r_f__max_depth': max_depth,\n",
    "               'r_f__min_samples_split': min_samples_split,\n",
    "               'r_f__min_samples_leaf': min_samples_leaf,\n",
    "               'r_f__criterion': criterion\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two pipeline: first for Linear SVM, Naive Bayes and Logistic Regression algorithms, second to train Random Forest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vec', TfidfVectorizer()),\n",
    "    ('clf', LinearSVC()),\n",
    "     ])\n",
    "\n",
    "pipe_rf = Pipeline([\n",
    "    ('vec', TfidfVectorizer()),\n",
    "    ('r_f',  RandomForestClassifier()),\n",
    "     ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-fold grid and random search for selected algorithms with “accuracy” performance measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 0.5, 'vec__max_features': 15000, 'vec__ngram_range': (1, 2)}</td>\n",
       "      <td>0.907825</td>\n",
       "      <td>0.967550</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 0.5, 'vec__max_features': 15000, 'vec__ngram_range': (1, 3)}</td>\n",
       "      <td>0.907200</td>\n",
       "      <td>0.967150</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 0.5, 'vec__max_features': 15000, 'vec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.906625</td>\n",
       "      <td>0.967262</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg', 'vec__max_features': 15000, 'vec__ngram_range': (1, 2)}</td>\n",
       "      <td>0.906200</td>\n",
       "      <td>0.946075</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs', 'vec__max_features': 15000, 'vec__ngram_range': (1, 2)}</td>\n",
       "      <td>0.906125</td>\n",
       "      <td>0.946075</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 0.1, 'vec__max_features': 15000, 'vec__ngram_range': (1, 3)}</td>\n",
       "      <td>0.906050</td>\n",
       "      <td>0.938262</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg', 'vec__max_features': 15000, 'vec__ngram_range': (1, 3)}</td>\n",
       "      <td>0.905925</td>\n",
       "      <td>0.945913</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs', 'vec__max_features': 15000, 'vec__ngram_range': (1, 3)}</td>\n",
       "      <td>0.905900</td>\n",
       "      <td>0.945900</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 0.1, 'vec__max_features': 15000, 'vec__ngram_range': (1, 2)}</td>\n",
       "      <td>0.905875</td>\n",
       "      <td>0.938737</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg', 'vec__max_features': 15000, 'vec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.905025</td>\n",
       "      <td>0.946075</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs', 'vec__max_features': 15000, 'vec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.946088</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 10, 'clf__penalty': 'l2', 'clf__solver': 'liblinear', 'vec__max_features': 15000, 'vec__ngram_range': (1, 3)}</td>\n",
       "      <td>0.904925</td>\n",
       "      <td>0.978100</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 0.1, 'vec__max_features': 15000, 'vec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.904700</td>\n",
       "      <td>0.938112</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 10, 'clf__penalty': 'l2', 'clf__solver': 'liblinear', 'vec__max_features': 15000, 'vec__ngram_range': (1, 2)}</td>\n",
       "      <td>0.904250</td>\n",
       "      <td>0.978662</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__solver': 'liblinear', 'vec__max_features': 15000, 'vec__ngram_range': (1, 2)}</td>\n",
       "      <td>0.904225</td>\n",
       "      <td>0.936587</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__solver': 'liblinear', 'vec__max_features': 15000, 'vec__ngram_range': (1, 3)}</td>\n",
       "      <td>0.904200</td>\n",
       "      <td>0.936412</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 1, 'vec__max_features': 15000, 'vec__ngram_range': (1, 2)}</td>\n",
       "      <td>0.903975</td>\n",
       "      <td>0.980275</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 1, 'vec__max_features': 15000, 'vec__ngram_range': (1, 3)}</td>\n",
       "      <td>0.903825</td>\n",
       "      <td>0.979837</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__solver': 'liblinear', 'vec__max_features': 15000, 'vec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.903000</td>\n",
       "      <td>0.936300</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 1, 'vec__max_features': 15000, 'vec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.902650</td>\n",
       "      <td>0.979000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 0.1, 'vec__max_features': 7000, 'vec__ngram_range': (1, 2)}</td>\n",
       "      <td>0.902550</td>\n",
       "      <td>0.931225</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg', 'vec__max_features': 7000, 'vec__ngram_range': (1, 2)}</td>\n",
       "      <td>0.902425</td>\n",
       "      <td>0.938500</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs', 'vec__max_features': 7000, 'vec__ngram_range': (1, 2)}</td>\n",
       "      <td>0.902425</td>\n",
       "      <td>0.938512</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 0.1, 'vec__max_features': 7000, 'vec__ngram_range': (1, 3)}</td>\n",
       "      <td>0.902400</td>\n",
       "      <td>0.930712</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg', 'vec__max_features': 7000, 'vec__ngram_range': (1, 3)}</td>\n",
       "      <td>0.902200</td>\n",
       "      <td>0.938012</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs', 'vec__max_features': 7000, 'vec__ngram_range': (1, 3)}</td>\n",
       "      <td>0.902200</td>\n",
       "      <td>0.938000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 10, 'clf__penalty': 'l2', 'clf__solver': 'liblinear', 'vec__max_features': 15000, 'vec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.902200</td>\n",
       "      <td>0.977062</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 0.1, 'vec__max_features': 7000, 'vec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.901725</td>\n",
       "      <td>0.931200</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__solver': 'liblinear', 'vec__max_features': 7000, 'vec__ngram_range': (1, 3)}</td>\n",
       "      <td>0.901700</td>\n",
       "      <td>0.929225</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__solver': 'liblinear', 'vec__max_features': 7000, 'vec__ngram_range': (1, 2)}</td>\n",
       "      <td>0.901550</td>\n",
       "      <td>0.929675</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 5, 'vec__max_features': 7000, 'vec__ngram_range': (1, 3)}</td>\n",
       "      <td>0.874825</td>\n",
       "      <td>0.986637</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 100, 'clf__penalty': 'l2', 'clf__solver': 'liblinear', 'vec__max_features': 7000, 'vec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.873825</td>\n",
       "      <td>0.993425</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 5, 'vec__max_features': 7000, 'vec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.873550</td>\n",
       "      <td>0.987488</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg', 'vec__max_features': 15000, 'vec__ngram_range': (1, 3)}</td>\n",
       "      <td>0.871400</td>\n",
       "      <td>0.879737</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs', 'vec__max_features': 15000, 'vec__ngram_range': (1, 3)}</td>\n",
       "      <td>0.871400</td>\n",
       "      <td>0.879750</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg', 'vec__max_features': 15000, 'vec__ngram_range': (1, 2)}</td>\n",
       "      <td>0.870850</td>\n",
       "      <td>0.879300</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs', 'vec__max_features': 15000, 'vec__ngram_range': (1, 2)}</td>\n",
       "      <td>0.870850</td>\n",
       "      <td>0.879300</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'liblinear', 'vec__max_features': 15000, 'vec__ngram_range': (1, 3)}</td>\n",
       "      <td>0.869500</td>\n",
       "      <td>0.877687</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'liblinear', 'vec__max_features': 15000, 'vec__ngram_range': (1, 2)}</td>\n",
       "      <td>0.869175</td>\n",
       "      <td>0.877075</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg', 'vec__max_features': 7000, 'vec__ngram_range': (1, 3)}</td>\n",
       "      <td>0.868425</td>\n",
       "      <td>0.876062</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs', 'vec__max_features': 7000, 'vec__ngram_range': (1, 3)}</td>\n",
       "      <td>0.868425</td>\n",
       "      <td>0.876050</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg', 'vec__max_features': 7000, 'vec__ngram_range': (1, 2)}</td>\n",
       "      <td>0.868075</td>\n",
       "      <td>0.875862</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs', 'vec__max_features': 7000, 'vec__ngram_range': (1, 2)}</td>\n",
       "      <td>0.868025</td>\n",
       "      <td>0.875862</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 100, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg', 'vec__max_features': 7000, 'vec__ngram_range': (1, 2)}</td>\n",
       "      <td>0.868000</td>\n",
       "      <td>0.998913</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 100, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs', 'vec__max_features': 7000, 'vec__ngram_range': (1, 2)}</td>\n",
       "      <td>0.867875</td>\n",
       "      <td>0.998913</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 100, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs', 'vec__max_features': 7000, 'vec__ngram_range': (1, 3)}</td>\n",
       "      <td>0.867750</td>\n",
       "      <td>0.998700</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 100, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg', 'vec__max_features': 7000, 'vec__ngram_range': (1, 3)}</td>\n",
       "      <td>0.867575</td>\n",
       "      <td>0.998700</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 100, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs', 'vec__max_features': 7000, 'vec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.866500</td>\n",
       "      <td>0.998763</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 100, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg', 'vec__max_features': 7000, 'vec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.866500</td>\n",
       "      <td>0.998738</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'liblinear', 'vec__max_features': 7000, 'vec__ngram_range': (1, 3)}</td>\n",
       "      <td>0.866375</td>\n",
       "      <td>0.873525</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs', 'vec__max_features': 7000, 'vec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.866300</td>\n",
       "      <td>0.873587</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg', 'vec__max_features': 7000, 'vec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.866300</td>\n",
       "      <td>0.873587</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'liblinear', 'vec__max_features': 7000, 'vec__ngram_range': (1, 2)}</td>\n",
       "      <td>0.866175</td>\n",
       "      <td>0.873212</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs', 'vec__max_features': 15000, 'vec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.866100</td>\n",
       "      <td>0.873750</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg', 'vec__max_features': 15000, 'vec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.866100</td>\n",
       "      <td>0.873775</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>{'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 10, 'vec__max_features': 7000, 'vec__ngram_range': (1, 2)}</td>\n",
       "      <td>0.864775</td>\n",
       "      <td>0.994000</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'liblinear', 'vec__max_features': 7000, 'vec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.864400</td>\n",
       "      <td>0.870937</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>{'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 10, 'vec__max_features': 7000, 'vec__ngram_range': (1, 3)}</td>\n",
       "      <td>0.864325</td>\n",
       "      <td>0.993575</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'liblinear', 'vec__max_features': 15000, 'vec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.864175</td>\n",
       "      <td>0.871825</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 10, 'vec__max_features': 7000, 'vec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.862750</td>\n",
       "      <td>0.993488</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                       params  \\\n",
       "16   {'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 0.5, 'vec__max_features': 15000, 'vec__ngram_range': (1, 2)}                                                                                                                                                      \n",
       "17   {'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 0.5, 'vec__max_features': 15000, 'vec__ngram_range': (1, 3)}                                                                                                                                                      \n",
       "15   {'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 0.5, 'vec__max_features': 15000, 'vec__ngram_range': (1, 1)}                                                                                                                                                      \n",
       "82   {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg', 'vec__max_features': 15000, 'vec__ngram_range': (1, 2)}    \n",
       "88   {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs', 'vec__max_features': 15000, 'vec__ngram_range': (1, 2)}        \n",
       "11   {'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 0.1, 'vec__max_features': 15000, 'vec__ngram_range': (1, 3)}                                                                                                                                                      \n",
       "83   {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg', 'vec__max_features': 15000, 'vec__ngram_range': (1, 3)}    \n",
       "89   {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs', 'vec__max_features': 15000, 'vec__ngram_range': (1, 3)}        \n",
       "10   {'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 0.1, 'vec__max_features': 15000, 'vec__ngram_range': (1, 2)}                                                                                                                                                      \n",
       "81   {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg', 'vec__max_features': 15000, 'vec__ngram_range': (1, 1)}    \n",
       "87   {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs', 'vec__max_features': 15000, 'vec__ngram_range': (1, 1)}        \n",
       "77   {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 10, 'clf__penalty': 'l2', 'clf__solver': 'liblinear', 'vec__max_features': 15000, 'vec__ngram_range': (1, 3)}     \n",
       "9    {'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 0.1, 'vec__max_features': 15000, 'vec__ngram_range': (1, 1)}                                                                                                                                                      \n",
       "76   {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 10, 'clf__penalty': 'l2', 'clf__solver': 'liblinear', 'vec__max_features': 15000, 'vec__ngram_range': (1, 2)}     \n",
       "94   {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__solver': 'liblinear', 'vec__max_features': 15000, 'vec__ngram_range': (1, 2)}    \n",
       "95   {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__solver': 'liblinear', 'vec__max_features': 15000, 'vec__ngram_range': (1, 3)}    \n",
       "22   {'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 1, 'vec__max_features': 15000, 'vec__ngram_range': (1, 2)}                                                                                                                                                        \n",
       "23   {'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 1, 'vec__max_features': 15000, 'vec__ngram_range': (1, 3)}                                                                                                                                                        \n",
       "93   {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__solver': 'liblinear', 'vec__max_features': 15000, 'vec__ngram_range': (1, 1)}    \n",
       "21   {'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 1, 'vec__max_features': 15000, 'vec__ngram_range': (1, 1)}                                                                                                                                                        \n",
       "7    {'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 0.1, 'vec__max_features': 7000, 'vec__ngram_range': (1, 2)}                                                                                                                                                       \n",
       "79   {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg', 'vec__max_features': 7000, 'vec__ngram_range': (1, 2)}     \n",
       "85   {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs', 'vec__max_features': 7000, 'vec__ngram_range': (1, 2)}         \n",
       "8    {'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 0.1, 'vec__max_features': 7000, 'vec__ngram_range': (1, 3)}                                                                                                                                                       \n",
       "80   {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg', 'vec__max_features': 7000, 'vec__ngram_range': (1, 3)}     \n",
       "86   {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs', 'vec__max_features': 7000, 'vec__ngram_range': (1, 3)}         \n",
       "75   {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 10, 'clf__penalty': 'l2', 'clf__solver': 'liblinear', 'vec__max_features': 15000, 'vec__ngram_range': (1, 1)}     \n",
       "6    {'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 0.1, 'vec__max_features': 7000, 'vec__ngram_range': (1, 1)}                                                                                                                                                       \n",
       "92   {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__solver': 'liblinear', 'vec__max_features': 7000, 'vec__ngram_range': (1, 3)}     \n",
       "91   {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__solver': 'liblinear', 'vec__max_features': 7000, 'vec__ngram_range': (1, 2)}     \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ...     \n",
       "26   {'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 5, 'vec__max_features': 7000, 'vec__ngram_range': (1, 3)}                                                                                                                                                         \n",
       "54   {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 100, 'clf__penalty': 'l2', 'clf__solver': 'liblinear', 'vec__max_features': 7000, 'vec__ngram_range': (1, 1)}     \n",
       "24   {'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 5, 'vec__max_features': 7000, 'vec__ngram_range': (1, 1)}                                                                                                                                                         \n",
       "119  {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg', 'vec__max_features': 15000, 'vec__ngram_range': (1, 3)}   \n",
       "125  {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs', 'vec__max_features': 15000, 'vec__ngram_range': (1, 3)}       \n",
       "118  {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg', 'vec__max_features': 15000, 'vec__ngram_range': (1, 2)}   \n",
       "124  {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs', 'vec__max_features': 15000, 'vec__ngram_range': (1, 2)}       \n",
       "131  {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'liblinear', 'vec__max_features': 15000, 'vec__ngram_range': (1, 3)}   \n",
       "130  {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'liblinear', 'vec__max_features': 15000, 'vec__ngram_range': (1, 2)}   \n",
       "116  {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg', 'vec__max_features': 7000, 'vec__ngram_range': (1, 3)}    \n",
       "122  {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs', 'vec__max_features': 7000, 'vec__ngram_range': (1, 3)}        \n",
       "115  {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg', 'vec__max_features': 7000, 'vec__ngram_range': (1, 2)}    \n",
       "121  {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs', 'vec__max_features': 7000, 'vec__ngram_range': (1, 2)}        \n",
       "43   {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 100, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg', 'vec__max_features': 7000, 'vec__ngram_range': (1, 2)}     \n",
       "49   {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 100, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs', 'vec__max_features': 7000, 'vec__ngram_range': (1, 2)}         \n",
       "50   {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 100, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs', 'vec__max_features': 7000, 'vec__ngram_range': (1, 3)}         \n",
       "44   {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 100, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg', 'vec__max_features': 7000, 'vec__ngram_range': (1, 3)}     \n",
       "48   {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 100, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs', 'vec__max_features': 7000, 'vec__ngram_range': (1, 1)}         \n",
       "42   {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 100, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg', 'vec__max_features': 7000, 'vec__ngram_range': (1, 1)}     \n",
       "128  {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'liblinear', 'vec__max_features': 7000, 'vec__ngram_range': (1, 3)}    \n",
       "120  {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs', 'vec__max_features': 7000, 'vec__ngram_range': (1, 1)}        \n",
       "114  {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg', 'vec__max_features': 7000, 'vec__ngram_range': (1, 1)}    \n",
       "127  {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'liblinear', 'vec__max_features': 7000, 'vec__ngram_range': (1, 2)}    \n",
       "123  {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs', 'vec__max_features': 15000, 'vec__ngram_range': (1, 1)}       \n",
       "117  {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg', 'vec__max_features': 15000, 'vec__ngram_range': (1, 1)}   \n",
       "31   {'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 10, 'vec__max_features': 7000, 'vec__ngram_range': (1, 2)}                                                                                                                                                        \n",
       "126  {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'liblinear', 'vec__max_features': 7000, 'vec__ngram_range': (1, 1)}    \n",
       "32   {'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 10, 'vec__max_features': 7000, 'vec__ngram_range': (1, 3)}                                                                                                                                                        \n",
       "129  {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'liblinear', 'vec__max_features': 15000, 'vec__ngram_range': (1, 1)}   \n",
       "30   {'clf': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 10, 'vec__max_features': 7000, 'vec__ngram_range': (1, 1)}                                                                                                                                                        \n",
       "\n",
       "     mean_test_score  mean_train_score  rank_test_score  \n",
       "16   0.907825         0.967550          1                \n",
       "17   0.907200         0.967150          2                \n",
       "15   0.906625         0.967262          3                \n",
       "82   0.906200         0.946075          4                \n",
       "88   0.906125         0.946075          5                \n",
       "11   0.906050         0.938262          6                \n",
       "83   0.905925         0.945913          7                \n",
       "89   0.905900         0.945900          8                \n",
       "10   0.905875         0.938737          9                \n",
       "81   0.905025         0.946075          10               \n",
       "87   0.905000         0.946088          11               \n",
       "77   0.904925         0.978100          12               \n",
       "9    0.904700         0.938112          13               \n",
       "76   0.904250         0.978662          14               \n",
       "94   0.904225         0.936587          15               \n",
       "95   0.904200         0.936412          16               \n",
       "22   0.903975         0.980275          17               \n",
       "23   0.903825         0.979837          18               \n",
       "93   0.903000         0.936300          19               \n",
       "21   0.902650         0.979000          20               \n",
       "7    0.902550         0.931225          21               \n",
       "79   0.902425         0.938500          22               \n",
       "85   0.902425         0.938512          22               \n",
       "8    0.902400         0.930712          24               \n",
       "80   0.902200         0.938012          25               \n",
       "86   0.902200         0.938000          25               \n",
       "75   0.902200         0.977062          27               \n",
       "6    0.901725         0.931200          28               \n",
       "92   0.901700         0.929225          29               \n",
       "91   0.901550         0.929675          30               \n",
       "..        ...              ...          ..               \n",
       "26   0.874825         0.986637          103              \n",
       "54   0.873825         0.993425          104              \n",
       "24   0.873550         0.987488          105              \n",
       "119  0.871400         0.879737          106              \n",
       "125  0.871400         0.879750          106              \n",
       "118  0.870850         0.879300          108              \n",
       "124  0.870850         0.879300          108              \n",
       "131  0.869500         0.877687          110              \n",
       "130  0.869175         0.877075          111              \n",
       "116  0.868425         0.876062          112              \n",
       "122  0.868425         0.876050          112              \n",
       "115  0.868075         0.875862          114              \n",
       "121  0.868025         0.875862          115              \n",
       "43   0.868000         0.998913          116              \n",
       "49   0.867875         0.998913          117              \n",
       "50   0.867750         0.998700          118              \n",
       "44   0.867575         0.998700          119              \n",
       "48   0.866500         0.998763          120              \n",
       "42   0.866500         0.998738          121              \n",
       "128  0.866375         0.873525          122              \n",
       "120  0.866300         0.873587          123              \n",
       "114  0.866300         0.873587          123              \n",
       "127  0.866175         0.873212          125              \n",
       "123  0.866100         0.873750          126              \n",
       "117  0.866100         0.873775          126              \n",
       "31   0.864775         0.994000          128              \n",
       "126  0.864400         0.870937          129              \n",
       "32   0.864325         0.993575          130              \n",
       "129  0.864175         0.871825          131              \n",
       "30   0.862750         0.993488          132              \n",
       "\n",
       "[132 rows x 4 columns]"
      ]
     },
     "execution_count": 1105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_m = GridSearchCV(pipe, param, cv = 3, return_train_score=True, scoring = 'accuracy', n_jobs=-1)\n",
    "search_m.fit(clean_data, y_train)\n",
    "\n",
    "df_m = pd.DataFrame.from_dict(search_m.cv_results_)\n",
    "df_m[['params', 'mean_test_score', 'mean_train_score', 'rank_test_score']].sort_values('rank_test_score', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the large hyperparameter space (576 different combinations), hyperparameter tuning has been performed with the Randomised search tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'vec__ngram_range': (1, 2), 'vec__max_features': 15000, 'r_f__n_estimators': 400, 'r_f__min_samples_split': 10, 'r_f__min_samples_leaf': 1, 'r_f__max_features': 'auto', 'r_f__max_depth': None, 'r_f__criterion': 'gini'}</td>\n",
       "      <td>0.863800</td>\n",
       "      <td>0.997763</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'vec__ngram_range': (1, 1), 'vec__max_features': 15000, 'r_f__n_estimators': 100, 'r_f__min_samples_split': 10, 'r_f__min_samples_leaf': 2, 'r_f__max_features': 'auto', 'r_f__max_depth': None, 'r_f__criterion': 'gini'}</td>\n",
       "      <td>0.859325</td>\n",
       "      <td>0.931350</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'vec__ngram_range': (1, 3), 'vec__max_features': 7000, 'r_f__n_estimators': 200, 'r_f__min_samples_split': 10, 'r_f__min_samples_leaf': 2, 'r_f__max_features': 'auto', 'r_f__max_depth': None, 'r_f__criterion': 'entropy'}</td>\n",
       "      <td>0.857075</td>\n",
       "      <td>0.936613</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'vec__ngram_range': (1, 2), 'vec__max_features': 7000, 'r_f__n_estimators': 200, 'r_f__min_samples_split': 2, 'r_f__min_samples_leaf': 1, 'r_f__max_features': 'auto', 'r_f__max_depth': None, 'r_f__criterion': 'entropy'}</td>\n",
       "      <td>0.856975</td>\n",
       "      <td>0.999913</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'vec__ngram_range': (1, 1), 'vec__max_features': 7000, 'r_f__n_estimators': 200, 'r_f__min_samples_split': 10, 'r_f__min_samples_leaf': 1, 'r_f__max_features': 'sqrt', 'r_f__max_depth': 60, 'r_f__criterion': 'gini'}</td>\n",
       "      <td>0.837325</td>\n",
       "      <td>0.934212</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'vec__ngram_range': (1, 2), 'vec__max_features': 15000, 'r_f__n_estimators': 10, 'r_f__min_samples_split': 2, 'r_f__min_samples_leaf': 4, 'r_f__max_features': 'sqrt', 'r_f__max_depth': None, 'r_f__criterion': 'gini'}</td>\n",
       "      <td>0.836150</td>\n",
       "      <td>0.871800</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'vec__ngram_range': (1, 1), 'vec__max_features': 7000, 'r_f__n_estimators': 100, 'r_f__min_samples_split': 5, 'r_f__min_samples_leaf': 4, 'r_f__max_features': 'auto', 'r_f__max_depth': 90, 'r_f__criterion': 'gini'}</td>\n",
       "      <td>0.833525</td>\n",
       "      <td>0.858413</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'vec__ngram_range': (1, 3), 'vec__max_features': 15000, 'r_f__n_estimators': 100, 'r_f__min_samples_split': 10, 'r_f__min_samples_leaf': 1, 'r_f__max_features': 'sqrt', 'r_f__max_depth': 30, 'r_f__criterion': 'gini'}</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.873400</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'vec__ngram_range': (1, 2), 'vec__max_features': 7000, 'r_f__n_estimators': 200, 'r_f__min_samples_split': 5, 'r_f__min_samples_leaf': 2, 'r_f__max_features': 'sqrt', 'r_f__max_depth': 30, 'r_f__criterion': 'gini'}</td>\n",
       "      <td>0.816775</td>\n",
       "      <td>0.847963</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'vec__ngram_range': (1, 2), 'vec__max_features': 7000, 'r_f__n_estimators': 400, 'r_f__min_samples_split': 5, 'r_f__min_samples_leaf': 4, 'r_f__max_features': 'auto', 'r_f__max_depth': 30, 'r_f__criterion': 'gini'}</td>\n",
       "      <td>0.809750</td>\n",
       "      <td>0.827625</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                          params  \\\n",
       "6  {'vec__ngram_range': (1, 2), 'vec__max_features': 15000, 'r_f__n_estimators': 400, 'r_f__min_samples_split': 10, 'r_f__min_samples_leaf': 1, 'r_f__max_features': 'auto', 'r_f__max_depth': None, 'r_f__criterion': 'gini'}     \n",
       "3  {'vec__ngram_range': (1, 1), 'vec__max_features': 15000, 'r_f__n_estimators': 100, 'r_f__min_samples_split': 10, 'r_f__min_samples_leaf': 2, 'r_f__max_features': 'auto', 'r_f__max_depth': None, 'r_f__criterion': 'gini'}     \n",
       "7  {'vec__ngram_range': (1, 3), 'vec__max_features': 7000, 'r_f__n_estimators': 200, 'r_f__min_samples_split': 10, 'r_f__min_samples_leaf': 2, 'r_f__max_features': 'auto', 'r_f__max_depth': None, 'r_f__criterion': 'entropy'}   \n",
       "9  {'vec__ngram_range': (1, 2), 'vec__max_features': 7000, 'r_f__n_estimators': 200, 'r_f__min_samples_split': 2, 'r_f__min_samples_leaf': 1, 'r_f__max_features': 'auto', 'r_f__max_depth': None, 'r_f__criterion': 'entropy'}    \n",
       "5  {'vec__ngram_range': (1, 1), 'vec__max_features': 7000, 'r_f__n_estimators': 200, 'r_f__min_samples_split': 10, 'r_f__min_samples_leaf': 1, 'r_f__max_features': 'sqrt', 'r_f__max_depth': 60, 'r_f__criterion': 'gini'}        \n",
       "8  {'vec__ngram_range': (1, 2), 'vec__max_features': 15000, 'r_f__n_estimators': 10, 'r_f__min_samples_split': 2, 'r_f__min_samples_leaf': 4, 'r_f__max_features': 'sqrt', 'r_f__max_depth': None, 'r_f__criterion': 'gini'}       \n",
       "1  {'vec__ngram_range': (1, 1), 'vec__max_features': 7000, 'r_f__n_estimators': 100, 'r_f__min_samples_split': 5, 'r_f__min_samples_leaf': 4, 'r_f__max_features': 'auto', 'r_f__max_depth': 90, 'r_f__criterion': 'gini'}         \n",
       "4  {'vec__ngram_range': (1, 3), 'vec__max_features': 15000, 'r_f__n_estimators': 100, 'r_f__min_samples_split': 10, 'r_f__min_samples_leaf': 1, 'r_f__max_features': 'sqrt', 'r_f__max_depth': 30, 'r_f__criterion': 'gini'}       \n",
       "2  {'vec__ngram_range': (1, 2), 'vec__max_features': 7000, 'r_f__n_estimators': 200, 'r_f__min_samples_split': 5, 'r_f__min_samples_leaf': 2, 'r_f__max_features': 'sqrt', 'r_f__max_depth': 30, 'r_f__criterion': 'gini'}         \n",
       "0  {'vec__ngram_range': (1, 2), 'vec__max_features': 7000, 'r_f__n_estimators': 400, 'r_f__min_samples_split': 5, 'r_f__min_samples_leaf': 4, 'r_f__max_features': 'auto', 'r_f__max_depth': 30, 'r_f__criterion': 'gini'}         \n",
       "\n",
       "   mean_test_score  mean_train_score  rank_test_score  \n",
       "6  0.863800         0.997763          1                \n",
       "3  0.859325         0.931350          2                \n",
       "7  0.857075         0.936613          3                \n",
       "9  0.856975         0.999913          4                \n",
       "5  0.837325         0.934212          5                \n",
       "8  0.836150         0.871800          6                \n",
       "1  0.833525         0.858413          7                \n",
       "4  0.825000         0.873400          8                \n",
       "2  0.816775         0.847963          9                \n",
       "0  0.809750         0.827625          10               "
      ]
     },
     "execution_count": 810,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_rf = RandomizedSearchCV(pipe_rf, random_grid, cv = 3, return_train_score=True, scoring = 'accuracy', n_jobs=-1)\n",
    "search_rf.fit(clean_data, y_train)\n",
    "\n",
    "df_rf = pd.DataFrame.from_dict(search_rf.cv_results_)\n",
    "df_rf[['params', 'mean_test_score', 'mean_train_score', 'rank_test_score']].sort_values(by=['rank_test_score'], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest score of about 90,8% obtained with Linear SVM algorithm, unigram and bigram sequence of words, size of vocabulary equal 15,000 and regularization hyperparameter (C) equal 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum validation accuracy\n",
      " \n",
      "SVM: 0.9078249605107684,\n",
      "Random Forest: 0.8637999829551761,\n",
      "Naive Bayes: 0.8999749461263155\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm_max = search_svm.cv_results_.get('mean_test_score').max()\n",
    "r_f_max = search_rf.cv_results_.get('mean_test_score').max() \n",
    "NB_max =  search_NB.cv_results_.get('mean_test_score').max()\n",
    "print ('Maximum validation accuracy\\n \\nSVM: {},\\nRandom Forest: {},\\nNaive Bayes: {}'.format(svm_max, r_f_max, NB_max))\n",
    "\n",
    "\n",
    "Accuracy = [svm_max, r_f_max, NB_max]\n",
    "Models = ['SVM','Random_Forest','Naive_Bayes']\n",
    "Accuracy_pos = np.arange(len(Models))\n",
    "plt.bar(Accuracy_pos, Accuracy)\n",
    "plt.xticks(Accuracy_pos, Models)\n",
    "plt.title('comparing the accuracy of each model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit and transform the training text data with obtained earlier best parameters of ngram_range and max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading vectorizer\n",
    "#vectorizer = joblib.load('tfidf_vectroizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features = 15000)\n",
    "X_train = vectorizer.fit_transform(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectroizer.pkl']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saving vectorizer\n",
    "#joblib.dump(vectorizer, 'tfidf_vectroizer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying best value for the 'C' hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mod_tf_idf = LinearSVC(C = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training time estimation for the Linear SVM algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507 ms ± 53.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "best_mod_tf_idf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_model_tfidf.pkl']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saving best model\n",
    "joblib_file = \"best_model_tfidf.pkl\"\n",
    "joblib.dump(best_mod_tf_idf, joblib_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming the test dataset with the same TF-IDF vectorizer and applying trained earlier Linear SVM model, the accuracy score around 91% have been achieved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading vectorizer\n",
    "#vectorizer = joblib.load('tfidf_vectroizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform(clean_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading best model\n",
    "model_tfidf = joblib.load('best_model_tfidf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset accuracy score: 0.91275 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       world       0.93      0.90      0.92      1000\n",
      "      sports       0.95      0.98      0.97      1000\n",
      "    business       0.89      0.87      0.88      1000\n",
      "    sci/tech       0.88      0.89      0.89      1000\n",
      "\n",
      "    accuracy                           0.91      4000\n",
      "   macro avg       0.91      0.91      0.91      4000\n",
      "weighted avg       0.91      0.91      0.91      4000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Creating the list with unique category names\n",
    "aux_df = test_data[['category_name', 'label']].drop_duplicates().sort_values('label')\n",
    "\n",
    "#prediction on the cleaned test dataset\n",
    "y_pred = model_tfidf.predict(X_test)\n",
    "\n",
    "print('Test dataset accuracy score:', accuracy_score(y_test, y_pred),'\\n')\n",
    "print(classification_report(y_test, y_pred, target_names=aux_df['category_name'].values))\n",
    "\n",
    "con = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(12,9))\n",
    "ax_cor_b = sns.heatmap(con.T, square=False, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=aux_df['category_name'].values, \n",
    "            yticklabels=aux_df['category_name'].values,\n",
    "            cmap=\"Blues\")\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')\n",
    "plt.title('Confusion matrix')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most accurately classified news topic is sports with f1-score equal to 0.97. More classification errors of the model occurred on the business and sci/tech topics both performing with 0.88 f1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Representation with Word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2vec is a word embedding technique with the general assumption that words in the corpus share similar contexts and meaning and therefore might have similar vector representation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to tokenised input text and transform it to list of lists format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = [row.split() for row in clean_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the overall size of corpus is relatively small (53202 unique words) and dataset was previously cleaned from stopwords, parameters such as size = 100 (the number of transformed vector’s dimensions), window = 5 (the maximum number of surrounding words to analyze), min_count = 1 (minimum count of words to proceed) and sg =1 (Skip-gram architecture) were selected for text transformation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Word2vec model\n",
    "#model_w2v = Word2Vec.load(\"word2vec.model\")\n",
    "#model_w2v.init_sims(replace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53202, 100)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_model_sg = Word2Vec(sent, size = 100, window = 5, min_count = 1, sg = 1)\n",
    "w_model_sg.init_sims(replace = True)\n",
    "w_model_sg.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving model\n",
    "#w_model_sg.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving weights\n",
    "filename = 'embedding_sg_word2vec.txt'\n",
    "w_model_sg.wv.save_word2vec_format(filename, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each word in the vocabulary transformed to the 100-dimensinal vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww = dict(zip(w_model_sg.wv.index2word, w_model_sg.wv.vectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expressions below demonstrate the 100-dimensional representation of the‘computer’ word and the most relevant context words estimated with cosine similarity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06388441, -0.08133382, -0.13676958,  0.10582004,  0.06654062,\n",
       "       -0.04945404,  0.07931393,  0.08044662, -0.19894224, -0.04958534,\n",
       "        0.08718207, -0.20376472, -0.02995504, -0.11479849, -0.09902271,\n",
       "        0.08149272, -0.02656364, -0.00617725, -0.01187406, -0.13356061,\n",
       "        0.05705734, -0.0504782 ,  0.21819203,  0.14567892,  0.11150423,\n",
       "        0.22995125, -0.13097145, -0.04231865, -0.05635202,  0.01697813,\n",
       "        0.09151268,  0.08142684,  0.09050979, -0.07395874,  0.02765094,\n",
       "       -0.10545062, -0.07931811,  0.00223664, -0.00463745, -0.06310347,\n",
       "        0.019389  ,  0.17977041,  0.17574738,  0.04723195,  0.0760856 ,\n",
       "       -0.00848501,  0.12051502,  0.15135323, -0.02821335, -0.07651005,\n",
       "       -0.05400637, -0.06249378, -0.03090185, -0.1311977 ,  0.13637047,\n",
       "       -0.01506626, -0.06128463,  0.07527307,  0.03063625, -0.02353359,\n",
       "       -0.135863  ,  0.11806294,  0.00530435, -0.06856249,  0.13208763,\n",
       "        0.02626646, -0.05626931, -0.24905108, -0.03653201, -0.05046824,\n",
       "       -0.01047773, -0.00566028,  0.03844219, -0.16854328, -0.18983673,\n",
       "       -0.00351789, -0.03189205, -0.00683244, -0.07032195, -0.11395986,\n",
       "        0.15294251, -0.10210698,  0.05696347,  0.02076365, -0.00205236,\n",
       "       -0.05633365,  0.00996392,  0.03992171,  0.09938776,  0.10060339,\n",
       "        0.06184255,  0.03764948,  0.06169024, -0.07659867,  0.02831339,\n",
       "       -0.15962256, -0.02482823, -0.03540504, -0.31427738,  0.04544675],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 1422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    w_model_sg.wv['computer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('computers', 0.7709169387817383),\n",
       " ('powerbook', 0.7192236185073853),\n",
       " ('hacker', 0.7096250057220459),\n",
       " ('personal', 0.7085227966308594),\n",
       " ('ibook', 0.6991468667984009),\n",
       " ('macintosh', 0.6917257308959961),\n",
       " ('aapl', 0.6909997463226318),\n",
       " ('pc', 0.6901720762252808),\n",
       " ('cupertino', 0.6838955879211426),\n",
       " ('accessed', 0.6793504953384399)]"
      ]
     },
     "execution_count": 1420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_model_sg.wv.most_similar('computer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, it is possible to calculate a similarity between two words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6137135"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_model_sg.wv.similarity('ibm', 'computer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expression below excludes an irrelevant word from the list of three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'computer'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_model_sg.wv.doesnt_match(['computer', 'paris', 'berlin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training ML algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One common approach to performing classification with ML algorithms is to calculate the average feature vector for each list of words in the training dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word averaging has been performed with defined by https://gist.github.com/susanli2016/dae5c9ff3cea5744822384881fc619dd#file-word_averaging\n",
    "function, which iterates through each row of the input text, extracts 100-dimensional vectorial representation and then calculates mean value by each column (axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_averaging(wv, words):\n",
    "    all_words, mean = set(), []\n",
    "    \n",
    "    for word in words:\n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        elif word in wv.vocab:\n",
    "            mean.append(wv.vectors_norm[wv.vocab[word].index])\n",
    "            all_words.add(wv.vocab[word].index)\n",
    "\n",
    "    if not mean:\n",
    "        logging.warning(\"cannot compute similarity with no input %s\", words)\n",
    "        return np.zeros(wv.vector_size,)\n",
    "\n",
    "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
    "    return mean\n",
    "\n",
    "def  word_averaging_list(wv, text_list):\n",
    "    return np.vstack([word_averaging(wv, post) for post in text_list ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 100)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_word_average_sg = word_averaging_list(w_model_sg.wv, np.array(sent))\n",
    "X_train_word_average_sg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying defined averaging function, transformed dataset with dimensions (40000,100) is ready to be processed through Linear SVM, Logistic Regression and Random Forest ML algorithms. Naïve Bayes has been excluded due to negative values in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [{ 'clf': [LinearSVC(max_iter = 7000)],\n",
    "          'clf__C':[0.5, 1, 10, 50, 100, 500]},\n",
    "          \n",
    "          {'clf': [LogisticRegression(max_iter = 9000)],\n",
    "           'clf__solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "           'clf__C': [1, 100, 500, 800]\n",
    "          }]\n",
    "\n",
    "# RandomForest Hyperparameters\n",
    "n_estimators = [100, 250, 400]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [30,60,90, None]\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "criterion = ['entropy', 'gini']\n",
    "\n",
    "\n",
    "r_f_par = {   'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'criterion': criterion\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = Pipeline([('clf', LinearSVC())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for TF-IDF method, Linear SVM, Logistic Regression and Random Forest algorithms were estimated and tuned through 3-fold grid and randomized search tools with ‘accuracy’ scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf': LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=9000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False), 'clf__C': 500, 'clf__solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "search_sg = GridSearchCV(pipe2, params,cv = 3,return_train_score = True, n_jobs = -1, scoring = 'accuracy')\n",
    "search_sg.fit(X_train_word_average_sg, y_train)\n",
    "print(search_sg.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'clf': LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=9000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 500, 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.886075</td>\n",
       "      <td>0.888675</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'clf': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=7000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 50}</td>\n",
       "      <td>0.886000</td>\n",
       "      <td>0.888600</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'clf': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=7000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 100}</td>\n",
       "      <td>0.885950</td>\n",
       "      <td>0.888625</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'clf': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=7000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 10}</td>\n",
       "      <td>0.885750</td>\n",
       "      <td>0.888575</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'clf': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=7000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 500}</td>\n",
       "      <td>0.885600</td>\n",
       "      <td>0.888475</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'clf': LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=9000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 100, 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.885500</td>\n",
       "      <td>0.888487</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'clf': LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=9000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 100, 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.885500</td>\n",
       "      <td>0.888537</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'clf': LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=9000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 100, 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.885450</td>\n",
       "      <td>0.888562</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'clf': LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=9000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 500, 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.885200</td>\n",
       "      <td>0.888537</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'clf': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=7000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 1}</td>\n",
       "      <td>0.885200</td>\n",
       "      <td>0.887712</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'clf': LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=9000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 10, 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.885150</td>\n",
       "      <td>0.888200</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'clf': LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=9000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 500, 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.885125</td>\n",
       "      <td>0.888487</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'clf': LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=9000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 10, 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.885100</td>\n",
       "      <td>0.887662</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'clf': LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=9000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 10, 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.885075</td>\n",
       "      <td>0.888162</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'clf': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=7000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 0.5}</td>\n",
       "      <td>0.885050</td>\n",
       "      <td>0.887287</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'clf': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=7000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 1000}</td>\n",
       "      <td>0.883600</td>\n",
       "      <td>0.885650</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'clf': LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=9000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.883050</td>\n",
       "      <td>0.884775</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'clf': LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=9000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.883050</td>\n",
       "      <td>0.884762</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'clf': LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=9000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.882300</td>\n",
       "      <td>0.883687</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'clf': LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=9000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.1, 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.875300</td>\n",
       "      <td>0.875825</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'clf': LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=9000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.1, 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.875300</td>\n",
       "      <td>0.875812</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'clf': LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=9000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.1, 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.872900</td>\n",
       "      <td>0.873450</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                            params  \\\n",
       "9   {'clf': LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=9000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 500, 'clf__solver': 'liblinear'}   \n",
       "3   {'clf': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=7000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 50}                                                                                                                                     \n",
       "4   {'clf': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=7000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 100}                                                                                                                                    \n",
       "2   {'clf': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=7000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 10}                                                                                                                                     \n",
       "5   {'clf': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=7000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 500}                                                                                                                                    \n",
       "12  {'clf': LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=9000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 100, 'clf__solver': 'liblinear'}   \n",
       "10  {'clf': LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=9000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 100, 'clf__solver': 'newton-cg'}   \n",
       "11  {'clf': LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=9000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 100, 'clf__solver': 'lbfgs'}       \n",
       "7   {'clf': LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=9000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 500, 'clf__solver': 'newton-cg'}   \n",
       "1   {'clf': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=7000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 1}                                                                                                                                      \n",
       "13  {'clf': LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=9000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 10, 'clf__solver': 'newton-cg'}    \n",
       "8   {'clf': LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=9000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 500, 'clf__solver': 'lbfgs'}       \n",
       "15  {'clf': LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=9000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 10, 'clf__solver': 'liblinear'}    \n",
       "14  {'clf': LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=9000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 10, 'clf__solver': 'lbfgs'}        \n",
       "0   {'clf': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=7000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 0.5}                                                                                                                                    \n",
       "6   {'clf': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=7000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0), 'clf__C': 1000}                                                                                                                                   \n",
       "16  {'clf': LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=9000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__solver': 'newton-cg'}   \n",
       "17  {'clf': LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=9000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__solver': 'lbfgs'}       \n",
       "18  {'clf': LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=9000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 1.0, 'clf__solver': 'liblinear'}   \n",
       "19  {'clf': LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=9000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.1, 'clf__solver': 'newton-cg'}   \n",
       "20  {'clf': LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=9000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.1, 'clf__solver': 'lbfgs'}       \n",
       "21  {'clf': LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=9000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), 'clf__C': 0.1, 'clf__solver': 'liblinear'}   \n",
       "\n",
       "    mean_test_score  mean_train_score  rank_test_score  \n",
       "9   0.886075         0.888675          1                \n",
       "3   0.886000         0.888600          2                \n",
       "4   0.885950         0.888625          3                \n",
       "2   0.885750         0.888575          4                \n",
       "5   0.885600         0.888475          5                \n",
       "12  0.885500         0.888487          6                \n",
       "10  0.885500         0.888537          7                \n",
       "11  0.885450         0.888562          8                \n",
       "7   0.885200         0.888537          9                \n",
       "1   0.885200         0.887712          10               \n",
       "13  0.885150         0.888200          11               \n",
       "8   0.885125         0.888487          12               \n",
       "15  0.885100         0.887662          13               \n",
       "14  0.885075         0.888162          14               \n",
       "0   0.885050         0.887287          15               \n",
       "6   0.883600         0.885650          16               \n",
       "16  0.883050         0.884775          17               \n",
       "17  0.883050         0.884762          17               \n",
       "18  0.882300         0.883687          19               \n",
       "19  0.875300         0.875825          20               \n",
       "20  0.875300         0.875812          20               \n",
       "21  0.872900         0.873450          22               "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.DataFrame.from_dict(search_sg.cv_results_)\n",
    "df3[['params', 'mean_test_score', 'mean_train_score', 'rank_test_score']].sort_values(by=['mean_test_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 400, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "r_f_clf = RandomForestClassifier()\n",
    "r_f2 = RandomizedSearchCV(r_f_clf, r_f_par, cv = 3, return_train_score = True, n_jobs = -1, scoring = 'accuracy')\n",
    "r_f2.fit(X_train_word_average_sg,y_train)\n",
    "print(r_f2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'n_estimators': 400, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'gini'}</td>\n",
       "      <td>0.890225</td>\n",
       "      <td>0.999400</td>\n",
       "      <td>210.500233</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'n_estimators': 250, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 90, 'criterion': 'entropy'}</td>\n",
       "      <td>0.889525</td>\n",
       "      <td>0.998237</td>\n",
       "      <td>150.769254</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'n_estimators': 400, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'gini'}</td>\n",
       "      <td>0.889250</td>\n",
       "      <td>0.995250</td>\n",
       "      <td>221.109260</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'n_estimators': 250, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 60, 'criterion': 'entropy'}</td>\n",
       "      <td>0.889025</td>\n",
       "      <td>0.977188</td>\n",
       "      <td>146.604610</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'n_estimators': 250, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': None, 'criterion': 'gini'}</td>\n",
       "      <td>0.888850</td>\n",
       "      <td>0.990925</td>\n",
       "      <td>119.318242</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'n_estimators': 400, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': None, 'criterion': 'gini'}</td>\n",
       "      <td>0.888275</td>\n",
       "      <td>0.963050</td>\n",
       "      <td>134.553910</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 90, 'criterion': 'gini'}</td>\n",
       "      <td>0.888100</td>\n",
       "      <td>0.981900</td>\n",
       "      <td>54.498798</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'gini'}</td>\n",
       "      <td>0.887075</td>\n",
       "      <td>0.962150</td>\n",
       "      <td>49.541311</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 90, 'criterion': 'entropy'}</td>\n",
       "      <td>0.886325</td>\n",
       "      <td>0.967188</td>\n",
       "      <td>54.791506</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': None, 'criterion': 'gini'}</td>\n",
       "      <td>0.885550</td>\n",
       "      <td>0.962475</td>\n",
       "      <td>51.079988</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                   params  \\\n",
       "2  {'n_estimators': 400, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'gini'}       \n",
       "7  {'n_estimators': 250, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 90, 'criterion': 'entropy'}    \n",
       "5  {'n_estimators': 400, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'gini'}       \n",
       "3  {'n_estimators': 250, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 60, 'criterion': 'entropy'}   \n",
       "0  {'n_estimators': 250, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': None, 'criterion': 'gini'}     \n",
       "9  {'n_estimators': 400, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': None, 'criterion': 'gini'}     \n",
       "8  {'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 90, 'criterion': 'gini'}      \n",
       "4  {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'gini'}     \n",
       "1  {'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 90, 'criterion': 'entropy'}   \n",
       "6  {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': None, 'criterion': 'gini'}     \n",
       "\n",
       "   mean_test_score  mean_train_score  mean_fit_time  rank_test_score  \n",
       "2  0.890225         0.999400          210.500233     1                \n",
       "7  0.889525         0.998237          150.769254     2                \n",
       "5  0.889250         0.995250          221.109260     3                \n",
       "3  0.889025         0.977188          146.604610     4                \n",
       "0  0.888850         0.990925          119.318242     5                \n",
       "9  0.888275         0.963050          134.553910     6                \n",
       "8  0.888100         0.981900          54.498798      7                \n",
       "4  0.887075         0.962150          49.541311      8                \n",
       "1  0.886325         0.967188          54.791506      9                \n",
       "6  0.885550         0.962475          51.079988      10               "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7 = pd.DataFrame.from_dict(r_f2.cv_results_)\n",
    "df7[['params', 'mean_test_score', 'mean_train_score','mean_fit_time', 'rank_test_score']].sort_values(by=['mean_test_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the highest score of about 88,8% achieved with Random Forest algorithm, this model has been overfitted with accuracy 99,99% on the training dataset. \n",
    "Thus, Logistic regression algorithm with accuracy scores 88,6% on validation and 88,8% on training datasets was selected as the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr = search_sg.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Completed training in 8.134909868240356 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "best_lr.fit(X_train_word_average_sg,y_train)\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print('\\n Completed training in {} seconds.'.format(elapsed),end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the best-performed model to the pkl-format file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_w2v.pkl']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib_file = \"best_w2v.pkl\"\n",
    "joblib.dump(best_lr, joblib_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming cleaned test dataset to the list of lists format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load cleaned test data\n",
    "clean_test_data = load_doc('clean_test_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sent = [row.split() for row in clean_test_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word averaging with devined earlier function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_word_average_sg = word_averaging_list(w_model_sg.wv,np.array(test_sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying Logistic Regression algorithm with the best tuned hyperparameters on the test dataset, the accuracy score 88,7% has been achieved. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best result has been achieved by sports news topic with 967 from 1000 correctly classified articles. The most classification errors (160) have been generated by Business topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "best_lr = joblib.load(\"best_w2v.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset accuracy score: 0.887 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       world       0.91      0.89      0.90      1000\n",
      "      sports       0.94      0.97      0.95      1000\n",
      "    business       0.85      0.84      0.84      1000\n",
      "    sci/tech       0.85      0.85      0.85      1000\n",
      "\n",
      "    accuracy                           0.89      4000\n",
      "   macro avg       0.89      0.89      0.89      4000\n",
      "weighted avg       0.89      0.89      0.89      4000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Creating the list with unique category names\n",
    "aux_df = test_data[['category_name', 'label']].drop_duplicates().sort_values('label')\n",
    "\n",
    "#prediction on the cleaned test dataset\n",
    "y_pred = best_lr.predict(X_test_word_average_sg)\n",
    "\n",
    "print('Test dataset accuracy score:', accuracy_score(y_test, y_pred),'\\n')\n",
    "print(classification_report(y_test, y_pred, target_names=aux_df['category_name'].values))\n",
    "\n",
    "con = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(12,9))\n",
    "ax_cor_b = sns.heatmap(con.T, square=False, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=aux_df['category_name'].values, \n",
    "            yticklabels=aux_df['category_name'].values,\n",
    "            cmap=\"Blues\")\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')\n",
    "plt.title('Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Embedding, LSTM, GRU, TimeDistributed, Bidirectional, GlobalMaxPooling1D\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to develop a Deep Learning (DL) model is to import a 100-dimensional vector with 53,202 unique words Word2vec model, pre-trained in the previous section. The function below imports pre-trained model and returns words inside the dictionary.                  \n",
    "The function build by https://machinelearningmastery.com/develop-word-embedding-model-predicting-movie-review-sentiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embedding as a dict\n",
    "def load_embedding(filename):\n",
    "    # load embedding into memory, skip first line\n",
    "    file = open(filename,'r')\n",
    "    lines = file.readlines()[1:]\n",
    "    file.close()\n",
    "    # create a map of words to vectors\n",
    "    embedding = dict()\n",
    "    for line in lines:\n",
    "        parts = line.split()\n",
    "        # key is string word, value is numpy array for vector\n",
    "        embedding[parts[0]] = asarray(parts[1:], dtype='float32')\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported_vocab = load_embedding('embedding_sg_word2vec.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to encode the training data by assigning integer number to each unique word and then convert each row of the source text to sequences of corresponding integers. Encoding has been performed with Keras Tokenizer tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load files and Tokenizer\n",
    "#clean_data = load_doc('clean_data.txt')\n",
    "#clean_test_data = load_doc('clean_test_data.txt')\n",
    "#tokenizer1 = joblib.load('C_LSTM_tokenizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer1 = Tokenizer()\n",
    "tokenizer1.fit_on_texts(clean_data)\n",
    "\n",
    "encoded_docs_tr = tokenizer1.texts_to_sequences(clean_data)\n",
    "encoded_docs_te = tokenizer1.texts_to_sequences(clean_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CNN_tokenizer.pkl']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saving Tokenizer\n",
    "#joblib.dump(tokenizer1, 'C_LSTM_tokenizer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling word_index attribute demonstrates how each unique word has been encoded with integer numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('new', 1),\n",
       " ('said', 2),\n",
       " ('us', 3),\n",
       " ('reuters', 4),\n",
       " ('ap', 5),\n",
       " ('first', 6),\n",
       " ('two', 7),\n",
       " ('world', 8),\n",
       " ('thursday', 9),\n",
       " ('oil', 10)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenizer1.word_index.items())[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the dimensions of the Keras embedding layer is the vocabulary size. This number equal to the number of unique words + 1 (because of Keras indexing from zero) is 53203"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53203"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer1.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras embedding layer has been built by mapping encoded integers to the vocabulary with pre-trained weights. The mapping process has been performed with get_weight_matrix function, where weight matrix with dimensions (53203, 100) mapped pre-trained weights with integer numbers.\n",
    "\n",
    "The function build by https://machinelearningmastery.com/develop-word-embedding-model-predicting-movie-review-sentiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weight matrix for the Embedding layer from a loaded embedding\n",
    "def get_weight_matrix(embedding, vocab):\n",
    "    # total vocabulary size plus 0 for unknown words\n",
    "    vocab_size = len(vocab) + 1\n",
    "    # define weight matrix dimensions with all 0\n",
    "    weight_matrix = zeros((vocab_size, 100))\n",
    "    # step vocab, store vectors using the Tokenizer's integer mapping\n",
    "    for word, i in vocab.items():\n",
    "        weight_matrix[i] = embedding.get(word)\n",
    "    return weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vectors = get_weight_matrix(imported_vocab, tokenizer1.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, training and testing datasets with appropriate to Keras format might be created with a defined earlier encoded-word dictionary. One of the Keras requirement is that input data should be a vector in the same length, therefore training and testing datasets zero-padded to 90 (maximum length of the vector in the training dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = max([len(s.split()) for s in clean_data])\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = pad_sequences(encoded_docs_tr, maxlen=max_length, padding='post')\n",
    "Xtest = pad_sequences(encoded_docs_te, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 90)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class attributes on both train and test datasets should be one-hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load label encoder\n",
    "#le = joblib.load('label_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "train_data['labeling'] = le.fit_transform(train_data['label'])\n",
    "test_data['labeling'] = le.transform(test_data['label'])\n",
    "num_classes = np.max(train_data['labeling']) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving label encoder\n",
    "#joblib.dump(le, 'label_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = keras.utils.to_categorical(train_data['labeling'],num_classes)\n",
    "ytest = keras.utils.to_categorical(test_data['labeling'],num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the present work, news articles classification task was performed with C-LSTM Neural Network model, which consists of both CNN and LSTM layers. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following parameters were applied to train C-LSTM model: \n",
    "“categorical_crossentropy” loss function – because of multiclass nature of the classification task and the one-hot representation of the labels. \n",
    "\"softmax\" output activation function, as it accommodates multiple classes into the normalized probabilistic vector with the total sum one.\n",
    "“accuracy” performance measure, since classes in the dataset well balanced.\n",
    "“batch_size” equal to 128, in order to increase the training speed of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another hyperparameters such as filters number, kernel size, dropout rate, optimizer, activation function and the number of hidden layers were tuned with Talos library https://autonomio.github.io/talos/#/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is define the function that builds, compiles and fits the Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_model(x_train, y_train, x_val, y_val, params):\n",
    "    model_CNN6 = Sequential()\n",
    "    model_CNN6.add(Embedding(vocab_size, 100, weights=[embedding_vectors], input_length=max_length, trainable=False))\n",
    "    model_CNN6.add(Dropout(0.3))\n",
    "    model_CNN6.add(Conv1D(filters=params['filters'], kernel_size = params['kernel_size'], activation='relu'))\n",
    "    model_CNN6.add(MaxPooling1D(pool_size=2))\n",
    "    model_CNN6.add(Dropout(0.3))\n",
    "    model_CNN6.add(LSTM(64, recurrent_dropout=0.15))\n",
    "    model_CNN6.add(Dropout(0.3))\n",
    "    model_CNN6.add(Dense(16, activation='relu'))\n",
    "\n",
    "\n",
    "    model_CNN6.add(Dense(4, activation='softmax'))\n",
    "    \n",
    "    model_CNN6.compile(loss='categorical_crossentropy', optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "\n",
    "    history = model_CNN6.fit(x_train, y_train, \n",
    "                        validation_data=[x_val, y_val],\n",
    "                        batch_size=128,\n",
    "                        callbacks=[talos.utils.live()],\n",
    "                        epochs=10,\n",
    "                        verbose=0)\n",
    "\n",
    "    return history, model_CNN6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'filters': [64, 128, 256],\n",
    "     'kernel_size': [4, 5, 8],\n",
    "     'optimizer': ['Nadam', 'Adam']\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the function and hyperparameters space, Talos might be initiated with Scan command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20% of the training dataset was selected for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [3:35:22<00:00, 822.24s/it]\n"
     ]
    }
   ],
   "source": [
    "exp8 = talos.Scan(x=Xtrain,\n",
    "               y=ytrain,\n",
    "               val_split = 0.2,\n",
    "               model=clf_model,\n",
    "               params=p,\n",
    "               experiment_name='clf8',\n",
    "               seed = 44,\n",
    "               round_limit = 18\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>optimizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>0.286478</td>\n",
       "      <td>0.899000</td>\n",
       "      <td>0.269526</td>\n",
       "      <td>0.905781</td>\n",
       "      <td>256</td>\n",
       "      <td>8</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>0.298538</td>\n",
       "      <td>0.895625</td>\n",
       "      <td>0.296623</td>\n",
       "      <td>0.900719</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0.290606</td>\n",
       "      <td>0.895500</td>\n",
       "      <td>0.280066</td>\n",
       "      <td>0.903188</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.300019</td>\n",
       "      <td>0.895500</td>\n",
       "      <td>0.288677</td>\n",
       "      <td>0.902344</td>\n",
       "      <td>256</td>\n",
       "      <td>8</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>0.293536</td>\n",
       "      <td>0.894750</td>\n",
       "      <td>0.284947</td>\n",
       "      <td>0.902594</td>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0.308003</td>\n",
       "      <td>0.893750</td>\n",
       "      <td>0.311851</td>\n",
       "      <td>0.894781</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.315393</td>\n",
       "      <td>0.893375</td>\n",
       "      <td>0.309617</td>\n",
       "      <td>0.895094</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>0.304281</td>\n",
       "      <td>0.893000</td>\n",
       "      <td>0.310762</td>\n",
       "      <td>0.895063</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>0.318829</td>\n",
       "      <td>0.891125</td>\n",
       "      <td>0.326161</td>\n",
       "      <td>0.890063</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0.307992</td>\n",
       "      <td>0.891125</td>\n",
       "      <td>0.310003</td>\n",
       "      <td>0.896031</td>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>0.321082</td>\n",
       "      <td>0.891000</td>\n",
       "      <td>0.334669</td>\n",
       "      <td>0.886594</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10</td>\n",
       "      <td>0.317294</td>\n",
       "      <td>0.889625</td>\n",
       "      <td>0.322137</td>\n",
       "      <td>0.891688</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.323350</td>\n",
       "      <td>0.888375</td>\n",
       "      <td>0.320613</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>0.322759</td>\n",
       "      <td>0.888250</td>\n",
       "      <td>0.328162</td>\n",
       "      <td>0.890250</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>0.319459</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.325117</td>\n",
       "      <td>0.890719</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.350608</td>\n",
       "      <td>0.886250</td>\n",
       "      <td>0.371882</td>\n",
       "      <td>0.877281</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.336040</td>\n",
       "      <td>0.886125</td>\n",
       "      <td>0.344987</td>\n",
       "      <td>0.884875</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>0.328732</td>\n",
       "      <td>0.883125</td>\n",
       "      <td>0.297502</td>\n",
       "      <td>0.898406</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    round_epochs  val_loss  val_accuracy      loss  accuracy  filters  \\\n",
       "17            10  0.286478      0.899000  0.269526  0.905781      256   \n",
       "16            10  0.298538      0.895625  0.296623  0.900719      256   \n",
       "2             10  0.290606      0.895500  0.280066  0.903188      128   \n",
       "10            10  0.300019      0.895500  0.288677  0.902344      256   \n",
       "14            10  0.293536      0.894750  0.284947  0.902594      256   \n",
       "8             10  0.308003      0.893750  0.311851  0.894781      128   \n",
       "4             10  0.315393      0.893375  0.309617  0.895094      128   \n",
       "7             10  0.304281      0.893000  0.310762  0.895063      256   \n",
       "12            10  0.318829      0.891125  0.326161  0.890063      128   \n",
       "3             10  0.307992      0.891125  0.310003  0.896031      256   \n",
       "15            10  0.321082      0.891000  0.334669  0.886594       64   \n",
       "13            10  0.317294      0.889625  0.322137  0.891688      128   \n",
       "9             10  0.323350      0.888375  0.320613  0.890000       64   \n",
       "5             10  0.322759      0.888250  0.328162  0.890250       64   \n",
       "6             10  0.319459      0.887500  0.325117  0.890719      128   \n",
       "1             10  0.350608      0.886250  0.371882  0.877281       64   \n",
       "0             10  0.336040      0.886125  0.344987  0.884875       64   \n",
       "11            10  0.328732      0.883125  0.297502  0.898406       64   \n",
       "\n",
       "    kernel_size optimizer  \n",
       "17            8     Nadam  \n",
       "16            4     Nadam  \n",
       "2             8     Nadam  \n",
       "10            8      Adam  \n",
       "14            5     Nadam  \n",
       "8             8      Adam  \n",
       "4             5     Nadam  \n",
       "7             4      Adam  \n",
       "12            5      Adam  \n",
       "3             5      Adam  \n",
       "15            8      Adam  \n",
       "13            4     Nadam  \n",
       "9             5     Nadam  \n",
       "5             4     Nadam  \n",
       "6             4      Adam  \n",
       "1             4      Adam  \n",
       "0             5      Adam  \n",
       "11            8     Nadam  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp8.data.head(18).sort_values(by=['val_accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best combinations of hyperparameters provided by round 14, with validation accuracy equal about 97,7 %. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A four-dimensional bar grid for visualizing hyperparameters relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABMYAAAEUCAYAAADAwzpPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3dfVhUdf7/8ddwMwwjYOAAmnIjWN6ltt5XWt6kpplhmltZmzelprluWbHpVtp3t8xqd1Njy/tEzbIbW9Eys6tMK1sy09a8gZBFIUQNREFgYH5/9NspFtRB5oB4no/r4rrgnM/5nPd8ruPnmnn5OWcsLpfLJQAAAAAAAMBkfOq7AAAAAAAAAKA+EIwBAAAAAADAlAjGAAAAAAAAYEoEYwAAAAAAADAlgjEAAAAAAACYEsEYAAAAAAAATIlgDLVy6NAhWSwWOZ1O97ann35a/fv3v6D+anNsXTpz5owaN26spk2bqry8/Jxtx4wZoz/96U91VBkAyZxzk8Vikc1m05EjR9zb/vSnP2nMmDEX1F+fPn20ePFiL1UHAAAAXJz86rsAXHqefPLJejm2LqWkpOg3v/mNcnJy9NFHH2nQoEH1XRKA8zDD3NS7d28999xzmjdvXn2XAgAAADQIrBiDJOnAgQPq37+/QkJCdNVVV2nDhg3ufWPGjNHw4cM1aNAgNW7cWD169NCBAwckyb2Cwmazyc/PTx9++KFmzZrlXqHw31Ubc+bMUVxcnIKDg/Xss88qOTlZHTt2VHBwsO644w73qo5fH/vb3/5Wfn5+7h+LxaL58+dLkrKzszVixAiFhYUpNjZWCxYsqFTvnXfeqWHDhikkJER/+ctfvD5eq1ev1pgxY3Tvvfdq9erVlfbl5eVp5MiRaty4seLj4/XZZ5+59+Xk5Kh9+/YKDg5WSEiI+vXrp4MHD7r3WywWPfXUU2rXrp3sdrumTp2qjRs3qmfPngoODtbAgQNVUFDg9dcDXKyYm2pmxowZeu2115SdnV1lX0VFhX7zm9/osssuU1BQkHr06KEdO3a49//www8aMGCAgoKC1L59e+3fv9+975tvvtGVV16pRo0aKTQ0VLfeeqvy8vIuaCwBAACAiwnBGFRWVqahQ4fqpptu0o8//qh58+bprrvuqhTYZGRkaPbs2crOzlbPnj01YcIESdKWLVsk/XxrodPp1MCBA6s9R1FRkb766it9+OGHmjFjht59912tW7dOBw4c0Pbt25WSklLlmDfeeENOp1NOp1NvvvmmoqOjdffdd6uiokK33HKLOnTooKysLL333nt6+umn9fnnn7uPTU1N1UMPPaQTJ07o4YcfrramHj16yGazVfvzww8/nHW8CgoKtHXrVo0cOVL33HOP3nvvPRUXF7v3jxkzRpdddpmysrL01VdfKT4+3r2vcePGWrNmjfLy8nT8+HH169dP06ZNq9R/dna2Nm/erG+//VbLli3TnDlztHDhQh0+fFjHjx/XsmXLzlobcClhbqrZ3CRJUVFRuvPOO/Xcc89V2WexWLRw4UJlZ2eroKBAU6ZM0dixYyX9HJoNHz5c1113nY4eParNmzfL4XC4j42Ojtb69euVn5+v7OxsNWvWTE899VStxxIAAACob9xKCe3YsUOnT5/WI488IovFon79+umWW27R6tWr3R98hg4dqp49e0qSHnvsMbVo0aJSGHQ+Tz75pPz8/ORwONSkSRNNmzZNcXFxklRplUd1MjMzNXHiRL333nsKDQ3Vjh07dOzYMT311FOyWCzq1KmTRo4cqY0bN+raa6+V9POKjr59+0qS/Pyqv8x/vVKiJt5++23dcsstCgoKUlBQkLp166aUlBTdfvvtOnr0qD744AP99NNPCgkJkSRdfvnl7mMDAgK0ZcsWPfjgg9q/f78KCgoUGRlZqf/ExEQ1b95cktSmTRuNHz9eHTt2lCT17dv3nGMFXEqYmy7MjBkz1KFDB/3xj3+stN1isWjv3r164okntHv3bhUUFOjMmTOqqKhQamqqfvzxRz355JPy8fGR3W5XkyZN3Mfa7Xa98cYb2rBhgzIyMlRQUKBrrrmmUv+1GUsAAACgvrBiDDpy5IiaN28ui8Xi3hYVFVXpAc6/9t9VBD/99NMFnc9ms8nlclX6u7S0tNq2TqdTd9xxh6ZPn+7+YJmZmamsrCwFBga6V1EsXrxYubm5F1RPTa1atUpr166Vw+GQw+HQ9u3btWrVKkk/r15p0qSJOxT7X3PnztVLL72kGTNmaP/+/dq4ceM5by+qyVgBlxrmpgsTHR2t3/72t1VWjb3++uuaPn26xo0bpz179mjPnj2qqKhQRUWFMjIyFBMTIx+f6t8W/OEPf9C7776rv/3tb0pPT9err77K3AUAAIBLAivGoObNm+vw4cNyuVzuD6BZWVm64oorqm2fkZEhm82mpk2buj+g/voDkDfNmDFDISEhSkxMrFRvy5YtlZ6eXqu+u3btql27dlW7b//+/ZVugfyvnJwc7d69W99//717rE6dOqUuXbooPz9fDodDBQUFKisrk7+/f5Xjt27dqj/84Q/uh/X/+gM/gMqYm6o629z0v2bOnKmOHTtq5MiR7m1bt27VPffco1GjRkmSCgsL3fscDof7mWHV2bp1q+bMmeMOAQEAAIBLBSvGoB49eigoKEhz585VUVGRPv74Y61fv1533XWXu01GRoZOnjyp48ePKzExUePGjZOPj48iIyNltVr1/vvvKz8/XydPnvRaXR988IFWrVql5OTkSgFS9+7dFRgYqJkzZ+rEiRMqLCzUp59+qq1bt9ao/9TUVPdzgv7352wfPNesWaMBAwYoKipKLVq0UIsWLdSmTRt17txZb731luLi4hQfH68XX3xRxcXF2rp1q7Zt2+Y+Pj4+Xtu2bVNxcbF++OEHzZkz58IGBzAB5ibP56b/FRMTo1GjRrlXs0o/zz9fffWVCgoK9OOPP1Z6RljPnj1VWFio1atXq6ioSOvXr9fevXsrHfvJJ5+orKxMu3fvVlJSUo1eEwAAAHCxIhiD/P39tX79em3atEmRkZH6/e9/r1WrVlValfHtt9+qXbt2atWqlZo0aaK5c+dKkqxWq1544QWNHTtW0dHR2rNnj9fqmjt3rnJycnT55Ze7v/1t5syZ8vf314YNG3Tw4EG1bdtWzZs318yZM896C5A3rV69WkOHDq2y/b/PPbJYLFq9erXeeOMNNW3aVM8//7yioqLc7Z544gkdO3ZMYWFhGj58uNq2bWt4zUBDxdxUOzNmzFBFRYX778mTJysyMlLNmjXT9ddfX2luatSokdasWaNZs2apRYsWWrNmjZo2bere/+KLL2rr1q0KCQnRpEmT3M89BAAAABo6i8uo+0xwyRgzZoxatGihP//5z/VdCgC4MTcBAAAAqC1WjAEAAAAAAMCUCMYAAAAAAABgStxKCQAAAAAAAFNixRgAAAAAAABMiWAMAAAAAAAApkQwBgAAAAAAAFMiGAMAAAAAAIApEYwBAAAAAADAlAjGAAAAAAAAYEoEYwAAAAAAADAlgjEAAAAAAACYEsEYAAAAAAAATIlgDAAAAAAAAKZEMAYAAAAAAABTIhgDAAAAAACAKRGMAQAAAAAAwJQIxgAAAAAAAGBKBGMAAAAAAAAwJYIxAAAAAAAAmJJffRcA4NK0bme6If0mdI43pF8Yx6hrQeJ6MJNxCzcb0u+wrnGG9CtxfQIAADQEBGMNmBmDB6M+GEnGfTjyxnj2mLLUC5VU1b5TlCH9SsZ+2AQaAoIcAAAA4OJHMPb/ETx4V0McT6ChaGj/vsw4V0nMVwAAAEBDQDAGAAC8gqARAAAADQ0P3wcAAAAAAIApEYwBAAAAAADAlAjGAAAAAAAAYEoEYwAAAAAAADAlgjEAAAAAAACYEsEYAAAAAAAATIlgDAAAAAAAAKZEMAYAAAAAAABTIhgDAAAAAACAKRGMAQAAAAAAwJQIxgAAAAAAAGBKBGMAAAAAAAAwJYIxAAAAAAAAmJJfXZwkPz9fycnJSktLk91u16BBg9SnT59q2x4+fFhr167Vf/7zH9lsNnXr1k0JCQny8SHDA2As5ioAAAAAMJc6CcZWrlwph8Oh8ePHKzc3V0lJSYqOjlZcXFyldhUVFXr55Zc1ePBgTZ06VSdOnNCrr76q0NBQ9e3bty5KBWBizFUAAAAAYC6GL20oLi7Wvn37lJCQILvdrpYtW6pr167auXNnlbZFRUUqKChQ+/bt5efnp4iICLVq1UrHjx83ukwAJsdcBQAAAADmY3gwlpeXJ5vNpsDAQPe2iIgI5ebmVmkbFBSknj17at68efrXv/6lw4cPKy0tTb179za6TAAmx1wFAAAAAOZj+K2UpaWl8vf3r7QtICBAJSUl1bbv1KmTcnJy9O2332rlypXq3LmzmjRpUus6CgsLz7k/wKe81ueojm95qSH9SlLZmSJD+j3fWHmC8fwF4+ldnoxncHBwjfttKHOV1PCuB6OuBan2/76MGkuJ8fS2S3E8L2SuAgAAgHcZHoxZrVaVl1d+o+x0OhUQEFCl7dGjR7Vq1SrNmjVLdrtdhYWFeuWVV7R+/XoNHz68VnWc781nSYVvrfo/m3JfqyH9SpK/zW5Iv954o854/oLx9C6jPkg2lLlKanjXg1HXglT768GosZQYT28z43gCAADAeIbfShkeHq6ioqJK/2uak5Oj8PDwKm0PHz6skJAQ2e0/v0kNDg5Wly5ddOTIEaPLBGByzFUAAAAAYD6GB2OBgYFq3bq1UlJSVFxcrMzMTKWmpqpz586SpNmzZ2vXrl2SpNjYWB07dkzbtm1TWVmZjh07pq+++krt2rUzukwAJsdcBQAAAADmY/itlJI0evRoJScnKzExUY0aNdKQIUPUqlUrSVJubq6Ki4slSWFhYZo0aZLee+89vfXWWwoKCtJ1112nvn371kWZAEyOuQoAAAAAzKVOgrGwsDBNmzat2n1JSUmV/m7Tpo3atGlTF2UBQCXMVQAAAABgLobfSgkAAAAAAABcjAjGAAAAAAAAYEoEYwAAAAAAADAlgjEAAAAAAACYEsEYAAAAAAAATIlgDAAAAAAAAKZEMAYAAAAAAABTIhgDAAAAAACAKRGMAQAAAAAAwJQIxgAAAAAAAGBKBGMAAAAAAAAwJYIxAAAAAAAAmBLBGAAAAAAAAEyJYAwAAAAAAACmRDAGAAAAAAAAU/Kr7wIAAAAAAABQcxUVFcrJydGxY8fkdDrru5yLlt1uV3x8vKxWa5V9BGMAAAAAAAANUHp6uiwWi9q0aSOr1SqLxVLfJV10KioqlJubq/T0dLVt27bKfm6lBAAAAAAAaIBOnjypuLg4BQQEEIqdhY+PjyIjI1VUVFT9/jquBwAAAAAAAF7i40O0cz7nGiNGDwAAAAAAAKZEMAYAAAAAAABTIhgDAAAAAACA26ZNm3TFFVcoICBAffv21dNPPy1JWr58uXr16uVuZ7FYlJaWVl9legXfSgkAAAAAAAC3P/7xj5o2bZqmTJmisrIyWa3W+i7JMKwYAwAAAAAAgCRp/Pjx2rVrl6ZNmyZ/f3/FxMRo+fLlVdr1799fktSmTRv5+flp4cKFkqQNGzbo6quvVnBwsK699lp999137mMsFov+/Oc/q2PHjgoICNB//vMfJScnq3Xr1rLb7Wrbtq1WrlxZJ6/zvwjGAAAAAAAAIElasmSJYmJitGnTJjmdTrVu3bradlu2bJEk7du3T06nUxMmTNDOnTs1duxYLViwQHl5eRoxYoRuv/12VVRUuI87ePCgUlJSVFhYKJfLpUmTJmnVqlU6duyYFi5cWKltXSAYAwAAAAAAQK0tWrRIkyZNUq9evWSz2fTwww8rKytLP/zwg7vNE088oejoaFmtVp05c0bFxcU6fPiw/Pz81Lt3b/3ud7+r05oJxgAAAAAAAFBrmZmZevbZZ2Wz2WSz2RQYGKiSkhLl5ORU275169ZKSkrS448/rpCQEPXq1Uupqal1WjPBGAAAAAAAAGrMx8dHLpfL/Xfz5s315JNP6syZM+6fsrIy9e7d+6x9TJo0Sd9//71+/PFHXX311Zo8eXJdlO5GMAYAAAAAAIAai4qK0qZNm1RYWKgTJ05o7Nixmj9/vjZv3qySkhJlZWVp2bJlOnXqVLXHf/HFF3r++eeVlZUlu92u0NBQhYWF1elrIBgDAAAAAABAjb3wwgv6y1/+osjISG3evFnXXnutFi1apMcff1xNmjRRjx499NFHH8nX17fa4yMjI/XRRx/p6quvlsPhUGpqqv7xj3/U6Wvw86TRiRMn6jyxAwAAAAAAQN07dOiQ+/dPPvnE/fuYMWM0ZswY998jR47UyJEjKx1766236tZbb62231/fdilJcXFx2rRpU63rrQ2PVoy1aNFCo0aN0gcffFDlRQAAAAAAAAANkUfBWHp6urp06aKHH35Y0dHR+tOf/qT09HSjawMAAAAAAAAM41Ew1qxZMyUmJmrv3r166623dPz4cXXt2lV9+vTRihUrVFxcbHSdAAAAAAAAgFfV6OH7paWlyszMVGZmps6cOaOQkBAtW7ZMzZo108SJE42qEQAAAAAAAPA6jx6+/8UXX2j58uV68803FR0drd/97ndatmyZIiMjJUn79+/XokWLznp8fn6+kpOTlZaWJrvdrkGDBqlPnz5nbb9r1y59+OGHys7Ols1m05w5c2r2qgDgAjBXAQAAAIC5eBSM3XLLLbrrrrv00UcfqUuXLlX2t27dWi+88MJZj1+5cqUcDofGjx+v3NxcJSUlKTo6WnFxcVXafvnll9q8ebPuvPNOxcTEqKioqAYvBwAuHHMVAAAAAJiLR7dSfv/995o2bVqlUOzo0aM6derUeY8tLi7Wvn37lJCQILvdrpYtW6pr167auXNnlbbl5eVat26dJk6cqFatWsnf31+NGzeuwcsBgAvDXAUAAAAA5uPRirH77rtPffr00UMPPeTe9vbbb+vjjz/W2rVrz3lsXl6ebDabAgMD3dsiIiK0d+/eKm0PHTqk8vJyvfXWW8rIyJCvr6+uvfZa3XLLLbJYLJ6+JgCoMeYqAAAAADAfj4Kxbdu2aenSpZW23XPPPXriiSfOe2xpaan8/f0rbQsICFBJSUmVtidOnJDNZtPQoUPVvHlzHT9+XC+//LKCgoLUr18/T0o9q8LCwnPuD/Apr1X/Z+NbXmpIv5JUdsaYW7fON1aeYDx/wXh6lyfjGRwcXON+G8pcJTW868Goa0Gq/b8vo8ZSYjy97VIczwuZqwAAAOBdHgVjjRo1UkVFRaVtp0+frvIhsjpWq1Xl5ZXfKDudTgUEBFRpa7FYFBQUpOjoaEk/r9bo3bu3vvvuu1p/2Dzfm8+SCt9a9X825b5WQ/qVJH+b3ZB+vfFGnfH8BePpXUZ9kGwoc5XU8K4Ho64FqfbXg1FjKTGe3mbG8QQAAIDxPHrG2IgRIzRmzBjt27dPxcXF+v777zVu3DglJCSc99jw8HAVFRVV+l/TnJwchYeHV2nrcDiUl5ensrIy97aKigoFBQV5UiYAXDDmKgAAAAAwH49WjD377LOaPn26OnfurJKSEtlsNt1xxx2aO3fueY8NDAxU69atlZKSooSEBB09elSpqamaOHGiJGn27Nm69dZbdfXVVysmJkahoaF66623dNttt+nEiRP67LPPNGrUqNq9SgA4D+YqAAAAAJeKHlOWnr+RAXa8PK5ezlsbHgVjNptNL7/8shYsWKBjx47J4XDU6AHTo0ePVnJyshITE9WoUSMNGTJErVq1kiTl5uaquLhY0s+3Jz3wwAN6/fXX9fjjjys4OFiDBw9Whw4dLuClAUDNMFcBAAAAgLl4FIxJP38o3L9/v5xOZ6XtnjxPJywsTNOmTat2X1JSUpW2U6ZM8bQsAPAa5ioAAAAAMBePgrHXXntNU6dO1enTp90Pmz5y5IjCw8N15MgRQwsEAAAAAAAAjOBRMPbMM8/oyy+/1LXXXqv09HT5+PjohRde0NGjR42uDwAAAAAAADCER99KmZWVpXbt2ik0NNQdhk2ZMkUrV640tDgAAAAAAADAKB4FY0FBQcrPz9c111yj5ORkSVJ2drb7QdQAAAAAAABAQ+NRMDZ8+HAdOXJEU6ZM0axZs9SlSxd1795df/jDH4yuDwAAAAAAAJeoTz/9VP3791dISIjsdrt++umnSvvXr18vf39/ffTRR4ac36NnjL366qvu3/fu3asdO3YoPj5eXbp0MaQoAAAAAAAAXNq2bNmi+++/X/Pnz1ffvn11+vRpBQcHu/dv27ZNM2bMUOPGjQ2rwaNgLDAwUD/99JNsNptiYmIUExNjWEEAAAAAAAC49D3yyCNavHix+vXrJ0my2+3ufbt379b999+vDRs2uPcbwaNbKaOiolRYWGhYEQAAAAAAADCP7Oxs7dmzRwsXLlRkZKSaNGmiiRMnqrS0VBkZGfrtb3+rNWvWKC4uztA6PArGHnjgAf3tb3+Ty+VSRUVFpR8AAAAAAACgJjIzM9WoUSNNmTJFWVlZ2r17t/bs2aPExETdeuutWrhwoTp16mR4HR4FY9OnT9ecOXPk5+cnf39/+fv7u38HAAAAAAAAasJisSggIEC9e/eW1WpV8+bNNX36dK1bt0779u3TgAEDZLPZZLPZlJmZqSFDhujRRx/1eh0ePWMsIyPD6ycGAAAAAACAOcXHx+v48ePKzc1VZGSkJMnpdKpp06ZVcqjY2FgtXrxYN954o9fr8CgY42H7AAAAAAAA8Jbw8HANGTJEkyZN0tKlS1VYWKjnn39eY8eOrdM6PArGxo0bd9Z9S5cu9VoxAAAAAAAAMIfXXntNDz74oOLi4hQUFKTJkydr8uTJdVqDR8FY8+bNq2x755131KFDB68XBAAAAAAAgEtfWFiYVq9efd52hw4dMqwGj4Kx//u//6uybeDAgZozZ47XCwIAAAAAAADqgkffSlmd7t27a/v27d6sBQAAAAAAAKgzHq0Y+/jjjyv9XVJSopSUFMXGxhpREwAAAAAAAGA4j4Kx8ePHV/rbarWqTZs2WrVqlSFFAQAAAAAAAEbzKBjLyMgwug4AAAAAAACgTnn0jLFnn322ygP4//GPf2jBggWGFAUAAAAAAAAYzaMVY4sXL9Y///nPStsGDBigwYMH68EHHzSkMAAAAAAAANTcjpfH1XcJDYZHK8aOHTum+Pj4StuioqJ09OhRQ4oCAAAAAAAAjOZRMNatWzclJydX2rZixQp16tTJkKIAAAAAAAAAo3l0K+Xf//53DRw4UIsXL1ZsbKwyMjJ06NAhvf/++0bXBwAAAAAAABjCo2Dsqquu0oEDB5SSkqKsrCwlJCTopptuUmhoqNH1AQAAAAAAAIbwKBhLSUnRsWPHNGbMGPe29957TyEhIerbt69RtQEAAAAAAACG8egZY08++aSio6MrbQsPD9djjz1mSFEAAAAAAACA0TwKxg4ePKjrrruu0rbu3btr3759hhQFAAAAAAAAGM2jYCw+Pl7/+te/Km378ssvq6wiAwAAAAAAABoKj54xNmvWLCUkJGj8+PGKjY3VoUOHtGTJEr300ktG1wcAAAAAAIAaGLdwc72cd+mEAfVy3trwaMVYQkKCNm7cqIKCAqWkpCg/P1/vvPOORo8ebXR9AAAAAAAAgCE8WjEm/fxMse7duxtZCwAAAAAAAFBnPArGSkpKNH/+fO3du1dOp7PSvhUrVhhSGAAAAAAAAGAkj26lnDhxorZu3apVq1YpPj5e8fHx+vLLL1VSUmJ0fQAAAAAAAIAhPFoxtnHjRqWnpysuLk6JiYmy2Wzq16+fnnnmGY9Okp+fr+TkZKWlpclut2vQoEHq06fPOY85deqU/vrXvyoqKkpjx4716DwAUBvMVQAAAABgLh4FY6dPn1ZQUJBatGihgwcPqkOHDrr22mv12WefeXSSlStXyuFwaPz48crNzVVSUpKio6MVFxdXbfuSkhK98sorslqtnr8SAKgl5ioAAAAAMBePbqWMjIzUf/7zHw0YMEAPP/yw9uzZo/nz56tFixbnPba4uFj79u1TQkKC7Ha7WrZsqa5du2rnzp3Vti8vL9eiRYvUvXt3XXXVVTV7NQBwgZirAAAAAKDunTx5Ug8++KDuvvtu97by8nLdcccdiomJkd1uV6dOnfTBBx+497tcLs2ePVtRUVEKCgrSddddpx07dlzQ+T0Kxl5++WVZrVY9/vjj8vHxUY8ePbR06VItX778vMfm5eXJZrMpMDDQvS0iIkK5ublV2rpcLr322mtq2bKlrr/+es9fBQDUEnMVAAAAANStf/7znwoLC1NSUlKl7eXl5YqKitKHH36o/Px8PfHEExo5cqSOHz8uSVq4cKHWrVunbdu26fjx47rttts0dOhQlZeX17gGj26lHDx4sPv3TZs2Vdm/ePFi3XfffdUeW1paKn9//0rbAgICqn1wf0pKiho1aqSbb77Zk7JqpLCw8Jz7A3xqPnie8C0vNaRfSSo7U2RIv+cbK08wnr9gPL3Lk/EMDg6ucb8NZa6SGt71YNS1INX+35dRYykxnt52KY7nhcxVAAAAl5Jhw4bJ6XRq1qxZSktLc2+3Wq16/vnn3X+PHDlSkydP1oEDB3TNNddoz5496tSpk2JiYiRJd999tx599FGdPHlSoaGhNarBo2DsfCZPnnzWYMxqtVZJ7JxOpwICAqq0zcnJ0Xfffaft27dLkioqKuRyubR//37NmTOnVjWe781nSYVvrfo/m3Jf45495G+zG9KvN96oM56/YDy9y6gPkg1lrpIa3vVg1LUg1f56MGosJcbT28w4ngAAAPhZenq6Tp48qVatWkmS7rvvPvXr10+TJ0/WAw88oOTkZE2ePLnGoZjkpWDM5XKddV94eLiKiopUWFjofoOYk5Oj8PDwKm0nTJhQ6e+UlBTl5eXxTW8ADMdcBQAAAAAXn5KSEt17772aOnWq+/NZXFycrrnmGhUVFWnUqFHKzc3Vhg0bLqh/j54xdj4Wi+Ws+wIDA9W6dWulpKSouLhYmZmZSk1NVefOnSVJs2fP1q5du7xRBgBcMOYqAAAAALi4lIOEYikAABSCSURBVJaWatSoUQoPD9ezzz7r3j516lT17NlTy5cv1/fff6958+ZpwIABOnbsWI3P4ZVg7HxGjx6to0ePKjExUa+88oqGDBniXv6Wm5ur4uLiuigDAM6JuQoAAAAALg4nT57UkCFD1KhRI61du1Z+fr/c9Pj111+rffv27r/vvvtu+fv7Kz09vcbn8cqtlOcTFhamadOmVbvvf7954NeGDh1qVEkAUAVzFQAAAADUv2PHjql///7q37+/XnzxxSp3Kvbp00fPPfecOnXqpBYtWmj58uWy2+3q0KFDjc9VJyvGAAAAAAAAgF97//335XA4NHfuXL311ltyOBxasmSJvvvuO+3evVvz5s2Tv7+//Pz85Ofnp/Hjx0uSnnvuOXXr1k29evVSeHi43n77bW3atEl2e82/WMnwh+8DAAAAAAAA/2vw4MFnfS7YubKmRo0aacGCBVqwYEGta/DKirGNGzd6oxsAAAAAAACgzpxzxdg999xzzm+clKQVK1ZowIABXi0KAAAAAAAAMNo5g7H/fhsbAAAAAAAAcKk5ZzD21FNP1VUdAAAAAAAAQJ3y+OH7qamp2rt3r5xOZ6Xt48aN83pRAAAAAAAAgNE8Csbmzp2rBQsWKDs7W71795Ykff3114qPjycYAwAAAAAAQIPkUTCWlJSk7du3q2PHjtq8ebP8/Py0fPlyff7550bXBwAAAAAAgBpYOoEvSfSUjyeNjh49qqioKIWHhys7O1uSNHr0aL3zzjuGFgcAAAAAAAAYxaNg7LLLLtOxY8fUq1cvvfTSS5Kkb775Rj4+Hh0OAAAAAAAAXHQ8upVy0qRJOnHihKZPn64+ffrotddeU1FRkTskAwAAAAAAABoaj4KxkydPqqysTO3bt9ehQ4f073//WzExMYqMjDS6PgAAAAAAAMAQHt0LWVRUpD59+qh79+5KTk7WlVdeSSgGAAAAAACABs2jYCwpKUnZ2dmaMWOGtmzZori4ON15553avHmz0fUBAAAAAAAAhvD46fn+/v5KSEjQ2rVrtW7dOn3xxRe66aabjKwNAAAAAAAAMIzHwdiPP/6ov/71r/rNb36jESNGaOjQofrqq6+MrA0AAAAAAAAwjEcP3x80aJC2bt2qG2+8UTNnztSwYcNktVqNrg0AAAAAAAA1tG5ner2cN6FzfL2ctzY8CsYGDBigFStW8MB9AAAAAAAAXDI8CsYeeeQRo+sAAAAAAAAA6pTHzxgDAAAAAAAALiUEYwAAAAAAADAlgjEAAAAAAACYEsEYAAAAAAAATIlgDAAAAAAAAHXqmWeeUdu2bWW32xUbG6sXXnih0v7Y2Fj5+vrKz8/P/fPOO++49x86dEijR49WeHi4rFarUlJSLqgOgjEAAAAAAADUKYvFoqVLl+rEiRNav369XnjhBb3//vuV2mzatElOp9P9c9ttt0mScnNzdcMNN+iaa67Rvn37lJ+fr+uvv/6C6vCr9SsBAAAAAAAAauDxxx93/96hQwddf/312rVrlwYPHnzeY+fMmaN7771XDz74YK3rYMUYAAAAAAAA6k15eblSU1PVrl27StuHDBmi4OBgdevWTR9++KF7+4YNG7R7927FxsYqJCREgwYNUmZm5gWdm2AMAAAAAAAA9SYxMVEREREaOnSoe9vWrVt1+vRp5eTkaMKECRo5cqSysrIkSZmZmRo0aJC+++47ZWdnq1WrVho+fPgFnZtgDAAAAAAAAPVizpw5+uc//6l169bJ19fXvT06Olr+/v4KCgrS/fffr5YtW+qzzz6T9PPzyW644QYFBQUpKChITz/9tL755htlZ2fX+PwEYwAAAAAAAKhTLpdLiYmJWr16tbZu3aqmTZues/2pU6fkcDgkSfHx8fr3v//t3ud0OuXj46PLLrusxnXw8H0AAAAAAADUqdGjR+vHH3/U1q1bqwRa33zzjT7++GONGjVKDodD8+fPl9PpVK9evSRJ48aN08yZM9WxY0ddfvnlmjFjhm677TbZ7fYa10EwBgAAAAAAgDr1+uuvy9fX170KTJJiY2OVlpamxo0ba+PGjXrmmWfkdDrVo0cPffDBB+7g66GHHlJhYaH69u2rkpISDRs2TIsXL76gOgjGAAAAAAAAUKdcLtdZ98XFxWnLli1n3e/j46NZs2Zp1qxZta6jToKx/Px8JScnKy0tTXa7XYMGDVKfPn2qbfvGG29o7969ys/PV2hoqAYPHqwePXrURZkATI65CgAAAADMpU6CsZUrV8rhcGj8+PHKzc1VUlKSoqOjFRcXV6WtzWbT/fffr6ZNmyojI0NJSUmKiorS5ZdfXhelAjAx5ioAAAAAMBfDv5WyuLhY+/btU0JCgux2u1q2bKmuXbtq586d1ba/9dZb1aJFC/n5+emKK65Q06ZNdeTIEaPLBGByzFUAAAAAYD6GB2N5eXmy2WwKDAx0b4uIiFBubu55jy0uLlZubq6aNWtmZIkAwFwFAAAAACZk+K2UpaWl8vf3r7QtICBAJSUl5zzO5XJp1apVatu2rVq0aFHrOgoLC8+5P8CnvNbnqI5veakh/UpS2ZkiQ/o931h5gvH8BePpXZ6MZ3BwcI37bShzldTwrgejrgWp9v++jBpLifH0tktxPC9krgIAAIB3GR6MWa1WlZdXfqPsdDoVEBBw1mNcLpfWrFmjn376SVOnTvVKHed781lS4euV8/yvcl+rIf1Kkr/Nbki/3nijznj+gvH0LqM+SDaUuUpqeNeDUdeCVPvrwaixlBhPbzPjeAIAAMB4hgdj4eHhKioqUmFhofsNYk5OjsLDw6ttX15erhUrVqigoEBTp06VzWYzukQAYK4CAAAAcMlI6Bxf3yU0GIY/YywwMFCtW7dWSkqKiouLlZmZqdTUVHXu3FmSNHv2bO3atUuSVFZWpgULFsjlcmnKlCl80ARQZ5irAAAAAMB8DF8xJkmjR49WcnKyEhMT1ahRIw0ZMkStWrWSJOXm5qq4uFiSdPLkSe3fv18+Pj6Vvgnuiiuu0LRp0+qiVAAmxlwFAAAAAOZSJ8FYWFjYWT8sJiUluX9v0qRJpb8BoC4xVwEAAABoaCoqKuTjY/gNgQ2ay+U66z5GDgAAAAAAoAGyWq0qKjLuW7YvFaWlpfLzq35tGMEYAAAAAABAA9S8eXOlp6fr1KlTqqioqO9yLkoVFRXKysqSw+Godn+d3EoJAAAAAAAA7woLC5MkZWRkqLS0tJ6ruXiFhISoWbNm1e4jGAMAAAAAAGigwsLC3AEZao5bKQEAAAAAAGBKBGMAAAAAAAAwJYIxAAAAAAAAmBLBGAAAAAAAAEyJYAwAAAAAAACmRDAGAAAAAAAAUyIYAwAAAAAAgCkRjAEAAAAAAMCUCMYAAAAAAABgSgRjAAAAAAAAMCWCMQAAAAAAAJgSwRgAAAAAAABMiWAMAAAAAAAApkQwBgAAAAAAAFMiGAMAAAAAAIApEYwBAAAAAADAlAjGAAAAAAAAYEoEYwAAAAAAADAlgjEAAAAAAACYEsEYAAAAAAAATIlgDAAAAAAAAKZEMAYAAAAAAABTIhgDAAAAAACAKRGMAQAAAAAAwJQIxgAAAAAAAGBKBGMAAAAAAAAwJYIxAAAAAAAAmBLBGAAAAAAAAEyJYAwAAAAAAACmRDAGAAAAAAAAU/Kri5Pk5+crOTlZaWlpstvtGjRokPr06VNt2+zsbK1atUpZWVm67LLLlJCQoM6dO9dFmQBMjrkKAAAAAMylToKxlStXyuFwaPz48crNzVVSUpKio6MVFxdXqZ3L5dKiRYvUvXt3TZ06VWlpaVqyZIliYmLUpEmTuigVgIkxVwEAAACAuRh+K2VxcbH27dunhIQE2e12tWzZUl27dtXOnTurtM3Oztbp06d10003yWaz6aqrrtIVV1yhb7/91ugyAZgccxUAAAAAmI/hwVheXp5sNpsCAwPd2yIiIpSbm1ul7dGjRxUaGiqLxeLeFhkZqaNHjxpdJgCTY64CAAAAAPMx/FbK0tJS+fv7V9oWEBCgkpISj9parVadOnWq1nX8+gNsXfrKwL6XGdj3xYrx9K5LeTxdLleN2pt9rpKMux7q+1qoL4ynd12q41nTuQoAAADeZXgwZrVaVV5eXmmb0+lUQEBAtW2dTmeVtlartdZ18MYTwLkwVwEAAACA+Rh+K2V4eLiKiopUWFjo3paTk6Pw8PAqbSMiIpSXl6eKiopKbSMiIowuE4DJMVcBAAAAgPkYHowFBgaqdevWSklJUXFxsTIzM5WamqrOnTtLkmbPnq1du3ZJki6//HKFhIRo06ZNOnPmjPbu3auDBw+qU6dORpcJwOSYqwAAAADAfCyuOrhv58SJE0pOTlZ6eroaNWqkgQMHqm/fvpKkyZMn65577tE111wjSTpy5IhWrlypI0eOqHHjxkpISFCXLl2MLhEAmKsAAAAAwGTqJBgDAAAAAAAALjaG30oJAAAAAAAAXIwM/1ZKeK6srEzz58+Xy+XS9OnT67ucBislJUXvv/++LBaLe9tVV12lSZMm1WNVDdvx48f15ptvKi0tTb6+vurQoYNGjRpV7Tc2whyYr2qPucr7mKsAAABQUwRjF4mKigotWbJETqdTvr6+9V1Og9e1a1eNHTu2vsu4ZCxdulRXXnmlxo8fr6KiIi1btkzr16/XyJEj67s01APmK+9hrvIu5ioAAADUFLdSXiRWr16tyMhI9e7du75LAarIzs5W27ZtZbVaddlll6l9+/Y6fvx4fZeFesJ8hYsVcxUAAABqihVjF4F3331XLpdLw4cP1xdffFHf5VwSvv76a33zzTcKDg5W9+7dNWzYsEq3K6Fm+vfvr6VLl+rmm2/WlVdeqZ07d7ICw6SYr7yLucq7mKsAAABQUwRj9ezzzz9Xbm6uJkyYUN+lXDJuuOEG9e/fX1arVUeOHNGyZcsUFBSk/v3713dpDVbbtm21Z88eZWRk6N1331XLli3VvHnz+i4LdYz5yruYq7yPuQoAAAA1ZXG5XK76LsLM3n77bX366afuvysqKuRyueTr66vnnntOgYGB9VjdpWHLli3697//rd///vf1XUqDVFRUpCeffFJ//OMf5XA4VFxcrBUrVsjX11f33XdffZeHOsR8ZSzmqtphrgIAAMCFYMVYPRsxYoRGjBjh/vuLL77Q559/zre8eVFJSYmCgoLqu4wGKy8vTxUVFXI4HJKkwMBA9ezZU+vWravnylDXmK+MxVxVO8xVAAAAuBA8fB+XnHXr1ikzM1NlZWU6dOiQPvvsM3Xr1q2+y2qwmjVrJn9/f6WkpKikpEQFBQXatm2b2rdvX9+lAQ0ac5V3MVcBAADgQrBiDJccp9OpRYsWqbCwUGFhYRo6dKg6dOhQ32U1WFarVVOmTNHbb7+tLVu2yGazqWvXrho2bFh9lwY0aMxV3sVcBQAAgAvBM8YAAAAAAABgStxKCQAAAAAAAFMiGAMAAAAAAIApEYwBAAAAAADAlAjGAAAAAAAAYEoEYwAAAAAAADAlgjEAAAAAAACYEsEYAAAAAAAATIlgDIaJjY3VRx99VK81LF++XL169apVH59++qn8/Py8VBEAAAAAALhYEIwB53HDDTfI6XTWdxkAAAAAAMDLCMZQJzIzMxUVFaXk5GQVFBRo/PjxioyM1OWXX64nnnhCLpdLkjRr1iwNHDhQd999t8LCwnT//ffrk08+UWRkpGbOnKno6Gg5HA79/e9/d/ddUlKiRx55RFFRUXI4HHrggQd05syZGteYlpamgQMHKiQkRM2aNdNdd90lSfrkk08UGxsrSUpKSpKfn5/7x8fHRyNGjPBqHQAAAAAAoG4QjMFwx48f10033aTExETdc889uvfee+Xj46MDBw5o+/btWrt2rV5//XV3+927d2vkyJHKycnRvHnzJEk//fSTHA6Hvv32W61du1aPPvqojh49KklKTEzUvn379PXXX2vv3r367rvv9Ne//rXGdU6aNEk9e/ZUdna2tm/friuvvLJKm8mTJ8vpdMrpdOrgwYNq0qSJHn30Ua/WAQAAAAAA6gbBGAx1+vRpDRkyRKNHj9aDDz6o3Nxcvf/++5o3b54aN26sli1baty4cdq4caP7mBtvvFEJCQkKCAhQYGCgJCkiIkIPPfSQQkND1bdvXzVu3FhpaWlyuVxatGiR5s2bp4iICEVERGjq1KmV+qtJrYcPH1ZRUZHi4uI0a9ass7YtKyvTHXfcoccee0w9e/b0ah0AAAAAAKBu8ERxGGrq1Kk6ceKE3nzzTUk/31JZWlqq0NBQdxuXy6Xrr7++Rv3abDaVlpYqLy9PRUVFateuXaX+YmJialzrq6++qscee0yxsbFq2rSppkyZounTp1fb9vHHH1eTJk30yCOPSJJX6wAAAAAAAHWDYAyGmjRpkgoKCnTzzTdr+/btat68uQICAlRYWCh/f/9a9+9wOGSz2XTgwAFFRUXVqq+OHTvqgw8+UHl5uT755BMNGjRIgwcPrtJu48aNWrNmjb755htZLBav1wEAAAAAAOoGt1LCUN27d9ecOXPUpk0bjRgxQhEREbrhhhs0ceJE5eTkqLi4WDt27NCGDRsuqH8fHx/97ne/0wMPPKAffvhBJSUl+vbbb90r1Gri97//vVJTU1VeXi6Hw6GAgACFhIRUanPkyBGNGzdOK1euVHh4uCF1AAAAAACAukEwBsNZLBYlJyfr1KlTmjBhglavXi1fX19169ZN4eHhmjJlisrKyi64/7/97W9q166d+vfvr9DQUI0ePVoFBQU17icgIEC33367GjdurDvuuENLlixRixYtKrVZsmSJcnNzdeONN7q/mbJXr15erQMAAAAAANQNi8vlctV3EQAAAAAAAEBdY8UYTGH//v3uFV7V/cycObO+SwQAAAAAAHWMFWMAAAAAAAAwJVaMAQAAAAAAwJQIxgAAAAAAAGBKBGMAAAAAAAAwJYIxAAAAAAAAmBLBGAAAAAAAAEyJYAwAAAAAAACm9P8A+SGkqEVh/cwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1226.6x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analyze_object = talos.Analyze(exp8)\n",
    "analyze_object.plot_bars('kernel_size', 'val_accuracy', 'filters','optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploy package clf9 have been saved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<talos.commands.deploy.Deploy at 0x16bfe42e8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saving talos results\n",
    "talos.Deploy(exp8, 'clf9', metric = 'val_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#restore talos results\n",
    "talos.Restore('clf9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to Talos results, the best combinations of hyperparameters represented with Nadam optimizer, 256 filters and 8 kernel size with validation accuracy 89,90 %. Next, C-LSTM model was trained with selected best hyperparameters (except kernel size, which was checked by trial and error approach), 26 epochs and batch size equal to 128 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 90, 100)           5320300   \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 90, 100)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 86, 256)           128256    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 43, 256)           0         \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 43, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_32 (LSTM)               (None, 64)                82176     \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 5,531,840\n",
      "Trainable params: 211,540\n",
      "Non-trainable params: 5,320,300\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/26\n",
      "32000/32000 [==============================] - 92s 3ms/step - loss: 0.7208 - accuracy: 0.6923 - val_loss: 0.4323 - val_accuracy: 0.8586\n",
      "Epoch 2/26\n",
      "32000/32000 [==============================] - 90s 3ms/step - loss: 0.4099 - accuracy: 0.8668 - val_loss: 0.3529 - val_accuracy: 0.8814\n",
      "Epoch 3/26\n",
      "32000/32000 [==============================] - 91s 3ms/step - loss: 0.3721 - accuracy: 0.8768 - val_loss: 0.3348 - val_accuracy: 0.8869\n",
      "Epoch 4/26\n",
      "32000/32000 [==============================] - 91s 3ms/step - loss: 0.3503 - accuracy: 0.8824 - val_loss: 0.3281 - val_accuracy: 0.8854\n",
      "Epoch 5/26\n",
      "32000/32000 [==============================] - 88s 3ms/step - loss: 0.3346 - accuracy: 0.8867 - val_loss: 0.3170 - val_accuracy: 0.8915\n",
      "Epoch 6/26\n",
      "32000/32000 [==============================] - 88s 3ms/step - loss: 0.3232 - accuracy: 0.8900 - val_loss: 0.3047 - val_accuracy: 0.8915\n",
      "Epoch 7/26\n",
      "32000/32000 [==============================] - 90s 3ms/step - loss: 0.3080 - accuracy: 0.8950 - val_loss: 0.2962 - val_accuracy: 0.8938\n",
      "Epoch 8/26\n",
      "32000/32000 [==============================] - 98s 3ms/step - loss: 0.2985 - accuracy: 0.8977 - val_loss: 0.2882 - val_accuracy: 0.8982\n",
      "Epoch 9/26\n",
      "32000/32000 [==============================] - 88s 3ms/step - loss: 0.2914 - accuracy: 0.8986 - val_loss: 0.2835 - val_accuracy: 0.9001\n",
      "Epoch 10/26\n",
      "32000/32000 [==============================] - 88s 3ms/step - loss: 0.2822 - accuracy: 0.9026 - val_loss: 0.2790 - val_accuracy: 0.8991\n",
      "Epoch 11/26\n",
      "32000/32000 [==============================] - 88s 3ms/step - loss: 0.2723 - accuracy: 0.9056 - val_loss: 0.2880 - val_accuracy: 0.8979\n",
      "Epoch 12/26\n",
      "32000/32000 [==============================] - 88s 3ms/step - loss: 0.2672 - accuracy: 0.9078 - val_loss: 0.2854 - val_accuracy: 0.8961\n",
      "Epoch 13/26\n",
      "32000/32000 [==============================] - 87s 3ms/step - loss: 0.2592 - accuracy: 0.9097 - val_loss: 0.2751 - val_accuracy: 0.8999\n",
      "Epoch 14/26\n",
      "32000/32000 [==============================] - 88s 3ms/step - loss: 0.2478 - accuracy: 0.9133 - val_loss: 0.2737 - val_accuracy: 0.9026\n",
      "Epoch 15/26\n",
      "32000/32000 [==============================] - 88s 3ms/step - loss: 0.2489 - accuracy: 0.9134 - val_loss: 0.2850 - val_accuracy: 0.8997\n",
      "Epoch 16/26\n",
      "32000/32000 [==============================] - 88s 3ms/step - loss: 0.2421 - accuracy: 0.9167 - val_loss: 0.2707 - val_accuracy: 0.9032\n",
      "Epoch 17/26\n",
      "32000/32000 [==============================] - 88s 3ms/step - loss: 0.2387 - accuracy: 0.9162 - val_loss: 0.2705 - val_accuracy: 0.9032\n",
      "Epoch 18/26\n",
      "32000/32000 [==============================] - 88s 3ms/step - loss: 0.2321 - accuracy: 0.9187 - val_loss: 0.2677 - val_accuracy: 0.9043\n",
      "Epoch 19/26\n",
      "32000/32000 [==============================] - 88s 3ms/step - loss: 0.2256 - accuracy: 0.9225 - val_loss: 0.2725 - val_accuracy: 0.9046\n",
      "Epoch 20/26\n",
      "32000/32000 [==============================] - 88s 3ms/step - loss: 0.2212 - accuracy: 0.9216 - val_loss: 0.2808 - val_accuracy: 0.9015\n",
      "Epoch 21/26\n",
      "32000/32000 [==============================] - 88s 3ms/step - loss: 0.2175 - accuracy: 0.9235 - val_loss: 0.2774 - val_accuracy: 0.9036\n",
      "Epoch 22/26\n",
      "32000/32000 [==============================] - 87s 3ms/step - loss: 0.2158 - accuracy: 0.9251 - val_loss: 0.2764 - val_accuracy: 0.9015\n",
      "Epoch 23/26\n",
      "32000/32000 [==============================] - 89s 3ms/step - loss: 0.2097 - accuracy: 0.9263 - val_loss: 0.2659 - val_accuracy: 0.9045\n",
      "Epoch 24/26\n",
      "32000/32000 [==============================] - 88s 3ms/step - loss: 0.2044 - accuracy: 0.9288 - val_loss: 0.2859 - val_accuracy: 0.9053\n",
      "Epoch 25/26\n",
      "32000/32000 [==============================] - 88s 3ms/step - loss: 0.2037 - accuracy: 0.9279 - val_loss: 0.2812 - val_accuracy: 0.9044\n",
      "Epoch 26/26\n",
      "32000/32000 [==============================] - 88s 3ms/step - loss: 0.1978 - accuracy: 0.9314 - val_loss: 0.2673 - val_accuracy: 0.9056\n",
      "\n",
      " Completed training in 2316.2732326984406 seconds.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(93)\n",
    "\n",
    "model_CNN5 = Sequential()\n",
    "model_CNN5.add(Embedding(vocab_size, 100, weights=[embedding_vectors], input_length=max_length, trainable=False))\n",
    "\n",
    "model_CNN5.add(Dropout(0.3))\n",
    "model_CNN5.add(Conv1D(filters=256, kernel_size = 5, activation='relu'))\n",
    "model_CNN5.add(MaxPooling1D(pool_size=2))\n",
    "model_CNN5.add(Dropout(0.3))\n",
    "\n",
    "model_CNN5.add(LSTM(64,recurrent_dropout=0.15))\n",
    "\n",
    "model_CNN5.add(Dropout(0.3))\n",
    "\n",
    "model_CNN5.add(Dense(16, activation='relu'))\n",
    "\n",
    "model_CNN5.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "print(model_CNN5.summary())\n",
    "\n",
    "\n",
    "# compile network\n",
    "model_CNN5.compile(loss = 'categorical_crossentropy', optimizer = 'Nadam', metrics = ['accuracy'])\n",
    "\n",
    "start = time.time()\n",
    "# fit network\n",
    "history = model_CNN5.fit(Xtrain, ytrain, epochs = 26, batch_size = 128, verbose=1, validation_split = 0.2)\n",
    "\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(10, 5))\n",
    "plt.legend(loc=6, prop={'size': 7})\n",
    "plt.grid(True)\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print('\\n Completed training in {} seconds.'.format(elapsed),end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the model\n",
    "#model_CNN5 = keras.models.load_model('model_CNN8.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, applying the trained model on the test dataset, the accuracy score 91.47% has been achieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 91.474998\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, acc = model_CNN5.evaluate(Xtest, ytest, verbose=0)\n",
    "print('Test Accuracy: %f' % (acc*100))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model\n",
    "#model_CNN5.save('model_CNN8.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
